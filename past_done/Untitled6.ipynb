{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e258e657-59f0-4eac-ba6d-a2ad048e9247",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: hanlp[full] in /opt/conda/lib/python3.11/site-packages (2.1.0b60)\n",
      "Requirement already satisfied: hanlp-common>=0.0.20 in /opt/conda/lib/python3.11/site-packages (from hanlp[full]) (0.0.20)\n",
      "Requirement already satisfied: hanlp-downloader in /opt/conda/lib/python3.11/site-packages (from hanlp[full]) (0.0.25)\n",
      "Requirement already satisfied: hanlp-trie>=0.0.4 in /opt/conda/lib/python3.11/site-packages (from hanlp[full]) (0.0.5)\n",
      "Requirement already satisfied: pynvml in /opt/conda/lib/python3.11/site-packages (from hanlp[full]) (11.5.3)\n",
      "Requirement already satisfied: sentencepiece>=0.1.91 in /opt/conda/lib/python3.11/site-packages (from hanlp[full]) (0.2.0)\n",
      "Requirement already satisfied: termcolor in /opt/conda/lib/python3.11/site-packages (from hanlp[full]) (2.4.0)\n",
      "Requirement already satisfied: toposort==1.5 in /opt/conda/lib/python3.11/site-packages (from hanlp[full]) (1.5)\n",
      "Requirement already satisfied: torch>=1.6.0 in /opt/conda/lib/python3.11/site-packages (from hanlp[full]) (2.0.1)\n",
      "Requirement already satisfied: transformers>=4.1.1 in /opt/conda/lib/python3.11/site-packages (from hanlp[full]) (4.44.2)\n",
      "Collecting fasttext-wheel==0.9.2 (from hanlp[full])\n",
      "  Obtaining dependency information for fasttext-wheel==0.9.2 from https://files.pythonhosted.org/packages/f6/13/94644fa56b36d5638e2c689f4506e2685a13c78765d03ae22294711460d4/fasttext_wheel-0.9.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "  Downloading fasttext_wheel-0.9.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (16 kB)\n",
      "Requirement already satisfied: networkx>=2.5.1 in /opt/conda/lib/python3.11/site-packages (from hanlp[full]) (3.1)\n",
      "Collecting penman==1.2.1 (from hanlp[full])\n",
      "  Obtaining dependency information for penman==1.2.1 from https://files.pythonhosted.org/packages/f6/6e/156e494cbe8d3cb9d07153e39f75142348661cc5e21642489b9706a01457/Penman-1.2.1-py3-none-any.whl.metadata\n",
      "  Downloading Penman-1.2.1-py3-none-any.whl.metadata (7.8 kB)\n",
      "Collecting perin-parser>=0.0.12 (from hanlp[full])\n",
      "  Downloading perin_parser-0.0.14.tar.gz (232 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.4/232.4 kB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting tensorflow<2.14,>=2.6.0 (from hanlp[full])\n",
      "  Obtaining dependency information for tensorflow<2.14,>=2.6.0 from https://files.pythonhosted.org/packages/df/0c/22cb1c82e0fbaca8c00c3e5e8f9cd1e1b618837f1c5641914fe251bdc9a5/tensorflow-2.13.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "  Downloading tensorflow-2.13.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.4 kB)\n",
      "Collecting pybind11>=2.2 (from fasttext-wheel==0.9.2->hanlp[full])\n",
      "  Obtaining dependency information for pybind11>=2.2 from https://files.pythonhosted.org/packages/04/e8/a22d08220cb5e230007d9b0c11e429c3b19d01315d1a99dbd45e3bf97386/pybind11-2.13.5-py3-none-any.whl.metadata\n",
      "  Downloading pybind11-2.13.5-py3-none-any.whl.metadata (9.5 kB)\n",
      "Requirement already satisfied: setuptools>=0.7.0 in /opt/conda/lib/python3.11/site-packages (from fasttext-wheel==0.9.2->hanlp[full]) (68.1.2)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.11/site-packages (from fasttext-wheel==0.9.2->hanlp[full]) (1.24.4)\n",
      "Requirement already satisfied: phrasetree>=0.0.9 in /opt/conda/lib/python3.11/site-packages (from hanlp-common>=0.0.20->hanlp[full]) (0.0.9)\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.11/site-packages (from perin-parser>=0.0.12->hanlp[full]) (1.11.2)\n",
      "Collecting absl-py>=1.0.0 (from tensorflow<2.14,>=2.6.0->hanlp[full])\n",
      "  Obtaining dependency information for absl-py>=1.0.0 from https://files.pythonhosted.org/packages/a2/ad/e0d3c824784ff121c03cc031f944bc7e139a8f1870ffd2845cc2dd76f6c4/absl_py-2.1.0-py3-none-any.whl.metadata\n",
      "  Downloading absl_py-2.1.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting astunparse>=1.6.0 (from tensorflow<2.14,>=2.6.0->hanlp[full])\n",
      "  Obtaining dependency information for astunparse>=1.6.0 from https://files.pythonhosted.org/packages/2b/03/13dde6512ad7b4557eb792fbcf0c653af6076b81e5941d36ec61f7ce6028/astunparse-1.6.3-py2.py3-none-any.whl.metadata\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl.metadata (4.4 kB)\n",
      "Collecting flatbuffers>=23.1.21 (from tensorflow<2.14,>=2.6.0->hanlp[full])\n",
      "  Obtaining dependency information for flatbuffers>=23.1.21 from https://files.pythonhosted.org/packages/41/f0/7e988a019bc54b2dbd0ad4182ef2d53488bb02e58694cd79d61369e85900/flatbuffers-24.3.25-py2.py3-none-any.whl.metadata\n",
      "  Downloading flatbuffers-24.3.25-py2.py3-none-any.whl.metadata (850 bytes)\n",
      "Collecting gast<=0.4.0,>=0.2.1 (from tensorflow<2.14,>=2.6.0->hanlp[full])\n",
      "  Obtaining dependency information for gast<=0.4.0,>=0.2.1 from https://files.pythonhosted.org/packages/b6/48/583c032b79ae5b3daa02225a675aeb673e58d2cb698e78510feceb11958c/gast-0.4.0-py3-none-any.whl.metadata\n",
      "  Downloading gast-0.4.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "Collecting google-pasta>=0.1.1 (from tensorflow<2.14,>=2.6.0->hanlp[full])\n",
      "  Obtaining dependency information for google-pasta>=0.1.1 from https://files.pythonhosted.org/packages/a3/de/c648ef6835192e6e2cc03f40b19eeda4382c49b5bafb43d88b931c4c74ac/google_pasta-0.2.0-py3-none-any.whl.metadata\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl.metadata (814 bytes)\n",
      "Collecting grpcio<2.0,>=1.24.3 (from tensorflow<2.14,>=2.6.0->hanlp[full])\n",
      "  Obtaining dependency information for grpcio<2.0,>=1.24.3 from https://files.pythonhosted.org/packages/47/1b/878a82c983a7f7cc8847075357ac41bbbf0617327f1e0aad26f71e65550c/grpcio-1.66.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "  Downloading grpcio-1.66.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.9 kB)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /opt/conda/lib/python3.11/site-packages (from tensorflow<2.14,>=2.6.0->hanlp[full]) (3.9.0)\n",
      "Collecting keras<2.14,>=2.13.1 (from tensorflow<2.14,>=2.6.0->hanlp[full])\n",
      "  Obtaining dependency information for keras<2.14,>=2.13.1 from https://files.pythonhosted.org/packages/2e/f3/19da7511b45e80216cbbd9467137b2d28919c58ba1ccb971435cb631e470/keras-2.13.1-py3-none-any.whl.metadata\n",
      "  Downloading keras-2.13.1-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting libclang>=13.0.0 (from tensorflow<2.14,>=2.6.0->hanlp[full])\n",
      "  Obtaining dependency information for libclang>=13.0.0 from https://files.pythonhosted.org/packages/1d/fc/716c1e62e512ef1c160e7984a73a5fc7df45166f2ff3f254e71c58076f7c/libclang-18.1.1-py2.py3-none-manylinux2010_x86_64.whl.metadata\n",
      "  Downloading libclang-18.1.1-py2.py3-none-manylinux2010_x86_64.whl.metadata (5.2 kB)\n",
      "Collecting numpy (from fasttext-wheel==0.9.2->hanlp[full])\n",
      "  Obtaining dependency information for numpy from https://files.pythonhosted.org/packages/82/19/321d369ede7458500f59151101470129d14f3b6768bb9b99bb7156f526b5/numpy-1.24.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "  Downloading numpy-1.24.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.6 kB)\n",
      "Collecting opt-einsum>=2.3.2 (from tensorflow<2.14,>=2.6.0->hanlp[full])\n",
      "  Obtaining dependency information for opt-einsum>=2.3.2 from https://files.pythonhosted.org/packages/bc/19/404708a7e54ad2798907210462fd950c3442ea51acc8790f3da48d2bee8b/opt_einsum-3.3.0-py3-none-any.whl.metadata\n",
      "  Downloading opt_einsum-3.3.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.11/site-packages (from tensorflow<2.14,>=2.6.0->hanlp[full]) (23.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /opt/conda/lib/python3.11/site-packages (from tensorflow<2.14,>=2.6.0->hanlp[full]) (4.23.3)\n",
      "Requirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.11/site-packages (from tensorflow<2.14,>=2.6.0->hanlp[full]) (1.16.0)\n",
      "Collecting tensorboard<2.14,>=2.13 (from tensorflow<2.14,>=2.6.0->hanlp[full])\n",
      "  Obtaining dependency information for tensorboard<2.14,>=2.13 from https://files.pythonhosted.org/packages/67/f2/e8be5599634ff063fa2c59b7b51636815909d5140a26df9f02ce5d99b81a/tensorboard-2.13.0-py3-none-any.whl.metadata\n",
      "  Downloading tensorboard-2.13.0-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting tensorflow-estimator<2.14,>=2.13.0 (from tensorflow<2.14,>=2.6.0->hanlp[full])\n",
      "  Obtaining dependency information for tensorflow-estimator<2.14,>=2.13.0 from https://files.pythonhosted.org/packages/72/5c/c318268d96791c6222ad7df1651bbd1b2409139afeb6f468c0f327177016/tensorflow_estimator-2.13.0-py2.py3-none-any.whl.metadata\n",
      "  Downloading tensorflow_estimator-2.13.0-py2.py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting typing-extensions<4.6.0,>=3.6.6 (from tensorflow<2.14,>=2.6.0->hanlp[full])\n",
      "  Obtaining dependency information for typing-extensions<4.6.0,>=3.6.6 from https://files.pythonhosted.org/packages/31/25/5abcd82372d3d4a3932e1fa8c3dbf9efac10cc7c0d16e78467460571b404/typing_extensions-4.5.0-py3-none-any.whl.metadata\n",
      "  Downloading typing_extensions-4.5.0-py3-none-any.whl.metadata (8.5 kB)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /opt/conda/lib/python3.11/site-packages (from tensorflow<2.14,>=2.6.0->hanlp[full]) (1.15.0)\n",
      "Collecting tensorflow-io-gcs-filesystem>=0.23.1 (from tensorflow<2.14,>=2.6.0->hanlp[full])\n",
      "  Obtaining dependency information for tensorflow-io-gcs-filesystem>=0.23.1 from https://files.pythonhosted.org/packages/66/7f/e36ae148c2f03d61ca1bff24bc13a0fef6d6825c966abef73fc6f880a23b/tensorflow_io_gcs_filesystem-0.37.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "  Downloading tensorflow_io_gcs_filesystem-0.37.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (14 kB)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.11/site-packages (from torch>=1.6.0->hanlp[full]) (3.12.4)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.11/site-packages (from torch>=1.6.0->hanlp[full]) (1.12)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.11/site-packages (from torch>=1.6.0->hanlp[full]) (3.1.2)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /opt/conda/lib/python3.11/site-packages (from torch>=1.6.0->hanlp[full]) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /opt/conda/lib/python3.11/site-packages (from torch>=1.6.0->hanlp[full]) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in /opt/conda/lib/python3.11/site-packages (from torch>=1.6.0->hanlp[full]) (11.7.101)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /opt/conda/lib/python3.11/site-packages (from torch>=1.6.0->hanlp[full]) (8.5.0.96)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /opt/conda/lib/python3.11/site-packages (from torch>=1.6.0->hanlp[full]) (11.10.3.66)\n",
      "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /opt/conda/lib/python3.11/site-packages (from torch>=1.6.0->hanlp[full]) (10.9.0.58)\n",
      "Requirement already satisfied: nvidia-curand-cu11==10.2.10.91 in /opt/conda/lib/python3.11/site-packages (from torch>=1.6.0->hanlp[full]) (10.2.10.91)\n",
      "Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in /opt/conda/lib/python3.11/site-packages (from torch>=1.6.0->hanlp[full]) (11.4.0.1)\n",
      "Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in /opt/conda/lib/python3.11/site-packages (from torch>=1.6.0->hanlp[full]) (11.7.4.91)\n",
      "Requirement already satisfied: nvidia-nccl-cu11==2.14.3 in /opt/conda/lib/python3.11/site-packages (from torch>=1.6.0->hanlp[full]) (2.14.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu11==11.7.91 in /opt/conda/lib/python3.11/site-packages (from torch>=1.6.0->hanlp[full]) (11.7.91)\n",
      "Requirement already satisfied: triton==2.0.0 in /opt/conda/lib/python3.11/site-packages (from torch>=1.6.0->hanlp[full]) (2.0.0)\n",
      "Requirement already satisfied: wheel in /opt/conda/lib/python3.11/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.6.0->hanlp[full]) (0.41.2)\n",
      "Requirement already satisfied: cmake in /opt/conda/lib/python3.11/site-packages (from triton==2.0.0->torch>=1.6.0->hanlp[full]) (3.27.5)\n",
      "Requirement already satisfied: lit in /opt/conda/lib/python3.11/site-packages (from triton==2.0.0->torch>=1.6.0->hanlp[full]) (16.0.6)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /opt/conda/lib/python3.11/site-packages (from transformers>=4.1.1->hanlp[full]) (0.24.6)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.11/site-packages (from transformers>=4.1.1->hanlp[full]) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.11/site-packages (from transformers>=4.1.1->hanlp[full]) (2023.8.8)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.11/site-packages (from transformers>=4.1.1->hanlp[full]) (2.31.0)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.11/site-packages (from transformers>=4.1.1->hanlp[full]) (0.4.4)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in /opt/conda/lib/python3.11/site-packages (from transformers>=4.1.1->hanlp[full]) (0.19.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.11/site-packages (from transformers>=4.1.1->hanlp[full]) (4.66.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers>=4.1.1->hanlp[full]) (2023.9.0)\n",
      "Collecting google-auth<3,>=1.6.3 (from tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.6.0->hanlp[full])\n",
      "  Obtaining dependency information for google-auth<3,>=1.6.3 from https://files.pythonhosted.org/packages/bb/fb/9af9e3f2996677bdda72734482934fe85a3abde174e5f0783ac2f817ba98/google_auth-2.34.0-py2.py3-none-any.whl.metadata\n",
      "  Downloading google_auth-2.34.0-py2.py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting google-auth-oauthlib<1.1,>=0.5 (from tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.6.0->hanlp[full])\n",
      "  Obtaining dependency information for google-auth-oauthlib<1.1,>=0.5 from https://files.pythonhosted.org/packages/4a/07/8d9a8186e6768b55dfffeb57c719bc03770cf8a970a074616ae6f9e26a57/google_auth_oauthlib-1.0.0-py2.py3-none-any.whl.metadata\n",
      "  Downloading google_auth_oauthlib-1.0.0-py2.py3-none-any.whl.metadata (2.7 kB)\n",
      "Collecting markdown>=2.6.8 (from tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.6.0->hanlp[full])\n",
      "  Obtaining dependency information for markdown>=2.6.8 from https://files.pythonhosted.org/packages/3f/08/83871f3c50fc983b88547c196d11cf8c3340e37c32d2e9d6152abe2c61f7/Markdown-3.7-py3-none-any.whl.metadata\n",
      "  Downloading Markdown-3.7-py3-none-any.whl.metadata (7.0 kB)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.6.0->hanlp[full])\n",
      "  Obtaining dependency information for tensorboard-data-server<0.8.0,>=0.7.0 from https://files.pythonhosted.org/packages/73/c6/825dab04195756cf8ff2e12698f22513b3db2f64925bdd41671bfb33aaa5/tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl.metadata\n",
      "  Downloading tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl.metadata (1.1 kB)\n",
      "Collecting werkzeug>=1.0.1 (from tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.6.0->hanlp[full])\n",
      "  Obtaining dependency information for werkzeug>=1.0.1 from https://files.pythonhosted.org/packages/4b/84/997bbf7c2bf2dc3f09565c6d0b4959fefe5355c18c4096cfd26d83e0785b/werkzeug-3.0.4-py3-none-any.whl.metadata\n",
      "  Downloading werkzeug-3.0.4-py3-none-any.whl.metadata (3.7 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests->transformers>=4.1.1->hanlp[full]) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests->transformers>=4.1.1->hanlp[full]) (2.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests->transformers>=4.1.1->hanlp[full]) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests->transformers>=4.1.1->hanlp[full]) (2023.7.22)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.11/site-packages (from jinja2->torch>=1.6.0->hanlp[full]) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.11/site-packages (from sympy->torch>=1.6.0->hanlp[full]) (1.3.0)\n",
      "Collecting cachetools<6.0,>=2.0.0 (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.6.0->hanlp[full])\n",
      "  Obtaining dependency information for cachetools<6.0,>=2.0.0 from https://files.pythonhosted.org/packages/a4/07/14f8ad37f2d12a5ce41206c21820d8cb6561b728e51fad4530dff0552a67/cachetools-5.5.0-py3-none-any.whl.metadata\n",
      "  Downloading cachetools-5.5.0-py3-none-any.whl.metadata (5.3 kB)\n",
      "Collecting pyasn1-modules>=0.2.1 (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.6.0->hanlp[full])\n",
      "  Obtaining dependency information for pyasn1-modules>=0.2.1 from https://files.pythonhosted.org/packages/13/68/8906226b15ef38e71dc926c321d2fe99de8048e9098b5dfd38343011c886/pyasn1_modules-0.4.0-py3-none-any.whl.metadata\n",
      "  Downloading pyasn1_modules-0.4.0-py3-none-any.whl.metadata (3.4 kB)\n",
      "Collecting rsa<5,>=3.1.4 (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.6.0->hanlp[full])\n",
      "  Obtaining dependency information for rsa<5,>=3.1.4 from https://files.pythonhosted.org/packages/49/97/fa78e3d2f65c02c8e1268b9aba606569fe97f6c8f7c2d74394553347c145/rsa-4.9-py3-none-any.whl.metadata\n",
      "  Downloading rsa-4.9-py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting requests-oauthlib>=0.7.0 (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.6.0->hanlp[full])\n",
      "  Obtaining dependency information for requests-oauthlib>=0.7.0 from https://files.pythonhosted.org/packages/3b/5d/63d4ae3b9daea098d5d6f5da83984853c1bbacd5dc826764b249fe119d24/requests_oauthlib-2.0.0-py2.py3-none-any.whl.metadata\n",
      "  Downloading requests_oauthlib-2.0.0-py2.py3-none-any.whl.metadata (11 kB)\n",
      "Collecting pyasn1<0.7.0,>=0.4.6 (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.6.0->hanlp[full])\n",
      "  Obtaining dependency information for pyasn1<0.7.0,>=0.4.6 from https://files.pythonhosted.org/packages/23/7e/5f50d07d5e70a2addbccd90ac2950f81d1edd0783630651d9268d7f1db49/pyasn1-0.6.0-py2.py3-none-any.whl.metadata\n",
      "  Downloading pyasn1-0.6.0-py2.py3-none-any.whl.metadata (8.3 kB)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.11/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.6.0->hanlp[full]) (3.2.2)\n",
      "Downloading fasttext_wheel-0.9.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.4/4.4 MB\u001b[0m \u001b[31m23.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading Penman-1.2.1-py3-none-any.whl (43 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.3/43.3 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tensorflow-2.13.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (479.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m479.7/479.7 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:03\u001b[0mm\n",
      "\u001b[?25hDownloading absl_py-2.1.0-py3-none-any.whl (133 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.7/133.7 kB\u001b[0m \u001b[31m17.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Downloading flatbuffers-24.3.25-py2.py3-none-any.whl (26 kB)\n",
      "Downloading gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
      "Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.5/57.5 kB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading grpcio-1.66.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.7/5.7 MB\u001b[0m \u001b[31m31.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading keras-2.13.1-py3-none-any.whl (1.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m29.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading libclang-18.1.1-py2.py3-none-manylinux2010_x86_64.whl (24.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.5/24.5 MB\u001b[0m \u001b[31m28.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading numpy-1.24.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.3/17.3 MB\u001b[0m \u001b[31m31.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.5/65.5 kB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pybind11-2.13.5-py3-none-any.whl (240 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m241.0/241.0 kB\u001b[0m \u001b[31m21.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tensorboard-2.13.0-py3-none-any.whl (5.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m32.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading tensorflow_estimator-2.13.0-py2.py3-none-any.whl (440 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m440.8/440.8 kB\u001b[0m \u001b[31m20.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tensorflow_io_gcs_filesystem-0.37.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.1/5.1 MB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading typing_extensions-4.5.0-py3-none-any.whl (27 kB)\n",
      "Downloading google_auth-2.34.0-py2.py3-none-any.whl (200 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m200.9/200.9 kB\u001b[0m \u001b[31m16.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading google_auth_oauthlib-1.0.0-py2.py3-none-any.whl (18 kB)\n",
      "Downloading Markdown-3.7-py3-none-any.whl (106 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.3/106.3 kB\u001b[0m \u001b[31m15.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl (6.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m31.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading werkzeug-3.0.4-py3-none-any.whl (227 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m227.6/227.6 kB\u001b[0m \u001b[31m17.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading cachetools-5.5.0-py3-none-any.whl (9.5 kB)\n",
      "Downloading pyasn1_modules-0.4.0-py3-none-any.whl (181 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m181.2/181.2 kB\u001b[0m \u001b[31m19.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading requests_oauthlib-2.0.0-py2.py3-none-any.whl (24 kB)\n",
      "Downloading rsa-4.9-py3-none-any.whl (34 kB)\n",
      "Downloading pyasn1-0.6.0-py2.py3-none-any.whl (85 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.3/85.3 kB\u001b[0m \u001b[31m16.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hBuilding wheels for collected packages: perin-parser\n",
      "  Building wheel for perin-parser (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for perin-parser: filename=perin_parser-0.0.14-py3-none-any.whl size=316652 sha256=1d8d1b843ca55fbef1b74e4540de8549ba50cd1ae11be5afd0972459ad0e7181\n",
      "  Stored in directory: /home/jovyan/.cache/pip/wheels/b7/d3/3e/fac4233f2d6207029647ec1a3808aef4c8a80fb1848652d6cf\n",
      "Successfully built perin-parser\n",
      "Installing collected packages: penman, libclang, flatbuffers, werkzeug, typing-extensions, tensorflow-io-gcs-filesystem, tensorflow-estimator, tensorboard-data-server, pybind11, pyasn1, numpy, markdown, keras, grpcio, google-pasta, gast, cachetools, astunparse, absl-py, rsa, requests-oauthlib, pyasn1-modules, opt-einsum, fasttext-wheel, perin-parser, google-auth, google-auth-oauthlib, tensorboard, tensorflow\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing_extensions 4.7.1\n",
      "    Uninstalling typing_extensions-4.7.1:\n",
      "      Successfully uninstalled typing_extensions-4.7.1\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.24.4\n",
      "    Uninstalling numpy-1.24.4:\n",
      "      Successfully uninstalled numpy-1.24.4\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "pydantic-core 2.20.1 requires typing-extensions!=4.7.0,>=4.6.0, but you have typing-extensions 4.5.0 which is incompatible.\n",
      "skimpy 0.0.11 requires click<9.0.0,>=8.1.6, but you have click 7.1.2 which is incompatible.\n",
      "pysal 23.1 requires momepy>=0.5.4, but you have momepy 0.0.0 which is incompatible.\n",
      "pysal 23.1 requires spaghetti>=1.7.2, but you have spaghetti 0.0.0 which is incompatible.\n",
      "pysal 23.1 requires tobler>=0.8.2, but you have tobler 0.0.0 which is incompatible.\n",
      "typeguard 4.1.4 requires typing-extensions>=4.7.0; python_version < \"3.12\", but you have typing-extensions 4.5.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed absl-py-2.1.0 astunparse-1.6.3 cachetools-5.5.0 fasttext-wheel-0.9.2 flatbuffers-24.3.25 gast-0.4.0 google-auth-2.34.0 google-auth-oauthlib-1.0.0 google-pasta-0.2.0 grpcio-1.66.0 keras-2.13.1 libclang-18.1.1 markdown-3.7 numpy-1.24.3 opt-einsum-3.3.0 penman-1.2.1 perin-parser-0.0.14 pyasn1-0.6.0 pyasn1-modules-0.4.0 pybind11-2.13.5 requests-oauthlib-2.0.0 rsa-4.9 tensorboard-2.13.0 tensorboard-data-server-0.7.2 tensorflow-2.13.1 tensorflow-estimator-2.13.0 tensorflow-io-gcs-filesystem-0.37.1 typing-extensions-4.5.0 werkzeug-3.0.4\n"
     ]
    }
   ],
   "source": [
    "!pip install hanlp[full] -U\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "208b7728-3ad5-4235-b6c2-f39a6af83533",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-24 03:16:41.642688: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-08-24 03:16:41.648158: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-08-24 03:16:41.728561: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-08-24 03:16:41.729595: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-08-24 03:16:42.712078: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/opt/conda/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of TFBertModel were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n",
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /tmp/jieba.cache\n",
      "Loading model cost 0.576 seconds.\n",
      "Prefix dict has been built successfully.\n"
     ]
    }
   ],
   "source": [
    "import hanlp\n",
    "import jieba\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "from wordcloud import WordCloud\n",
    "import contextlib\n",
    "import io  # 导入 io 模块\n",
    "\n",
    "# 初始化 HanLP 模型\n",
    "recognizer = hanlp.load(hanlp.pretrained.ner.MSRA_NER_BERT_BASE_ZH)\n",
    "\n",
    "# 读取 Excel 文件\n",
    "file_path = 'Blossoms_DouBan_Review.xlsx'\n",
    "df = pd.read_excel(file_path)\n",
    "\n",
    "# 添加自定义词汇\n",
    "custom_words = ['和平饭店', '至真园', '泡饭', '排骨年糕', '蓝鱼秃肺拼海参', '红烧划水', '定胜糕', '油墩子', '川沙鸡爪', \n",
    "                '牛河', '黄鱼面', '饭团', '鹤针', '舟王炒饭', '炎王蛇', '三文鱼', '鲶鱼', '茶叶蛋', '火锅', '辣肉面', '包子']\n",
    "for word in custom_words:\n",
    "    jieba.add_word(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "170e6198-9bfd-4308-b2b1-924c546609ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-08-24 03:17:45 WARNING Input tokens 上一次看国产剧竟然也是胡哥的琅琊榜。所以胡歌就是好剧的代名词？我觉得应该是，有的人为拍戏只为了钱，有的人还为了自己的名声，有的人两者都顾，有的人更顾及名声。就像游本昌说他目前80多岁，就拍过两部好戏，一部济公，一部繁花。中间等了几十年的跨度。或者就像刚开始的宝总，为了第一桶金，可以啥都干，吃各种苦，但是挣到了第一桶金，或者成名之后，就更多是随心了，不在乎挣多挣少，哪怕是亏本。当然里面的情感戏确实更真实，也很经典，都在为自由和理想奋斗，我只服典句大师葛老师，“感情这东西，头一转就是另外一条路了，过去了就是过去了，再回不来了，该怎么样就怎么样吧！”，“一种选择，一种人生，不是你晓得对错就能逃掉的”，“其实感情这东西就是这样，就好比两个人约好一起去逛庙会，两个人讲好了呀，长夜慢慢，一起玩到天亮，结果这个朋友有事先走了，他呢，也找到另外一个伙伴，继续玩下去，但是呢，他心里永远会记得，和之前那个人看过，讲过，笑过！”\n",
      "男女之事，源自天时地利，差一分就是空门！\n",
      "投诉 exceed the max sequence length of 126. The exceeded part will be truncated and ignored. You are recommended to split your long text into several sentences within 126 tokens beforehand.\n",
      "2024-08-24 03:17:46 WARNING Input tokens 前文：天上月与水中月——细说87年的阿宝与雪芝\n",
      "雪芝去香港后，阿宝幻想过无数次与她的重逢，其实就是幻想过无数个雪芝的样子，但是，他从未想过雪芝会这么爱慕虚荣讲究物质，甚至当面嘲讽自己。这简直颠覆了阿宝对于爱情和自我的全部认知。所以他后来回忆雪芝时，总说自己看不清她。所谓看不清，就是极度抗拒雪芝对他的态度，却又想不出，除了最不愿意接受的理由外，雪芝为什么要这么残忍地对待他。\n",
      "阿宝为什么会这样想呢？因为1978年与他谈恋爱的那个雪芝，不但不虚荣，而且不虚荣到了出尘脱俗的地步。当时男女恋爱，单位性质极重要。阿宝是小集体工厂的机修工，雪芝是全民单位售票员，天差地别。更有甚者，阿宝爸爸还没有平反，他一个在集体小厂做机修工的“反革命子女”，自己都觉得跟雪芝谈恋爱不可能。但是雪芝一点都不在乎，一直跟阿宝大大方方交往，甚至直接到阿宝工人新村的家里找他。\n",
      "阿宝家住的“两万户”，是雪芝哥哥口中的“垃圾地角垃圾房”，门口还天天挂着阿宝爸爸“我破坏革命死不认账罪该万死”的认罪书。但是我们看看雪芝跟阿宝在这样的陋室里，都是怎么相处的:\n",
      "“下午一点钟，天气阴冷，飘小清雪，新村里冷冷清清，房间里静。阿宝倒一杯开水，两人看邮票，看丰子恺为民国小学生解释《九成宫》。后来，雪芝发现窗外的腊梅。阿宝说，邻居种的。雪芝说，嗯，已经开了，枝桠有笔墨气。阿宝说，我折一枝。雪芝说，看看就好了。阿宝不响。雪芝说，真静。阿宝说，落雪了。雪芝说，花开得精神，寒花最宜初雪，雪霁，新月。两个人看花，玻璃衍出一团哈气，雪芝开一点窗，探出去，雪气清冽，有淡淡梅香。雪芝说，天生天化，桃三李四梅十二，梅花最费功夫。阿宝说，这是腊梅，也可以叫真腊，黄梅。雪芝说，也算梅花呀。阿宝说，我记得一句，寒花只作去年香。雪芝说，梅花开，寒香接袂，千株万本，单枝数房，一样好看。阿宝说，嗯。雪芝不响。阿宝说，我有棋子。雪芝摇手说，算了。阿宝说，为啥呢。雪芝嫣然说，阿宝不认真的。阿宝笑笑。雪芝说，我只记得一个对子，棋倦杯频昼永，粉香花艳清明。雪芝伸手，点到窗玻璃上，写几个字。阿宝觉得，眼前的雪芝，清幽出尘，灵心慧舌，等于一枝白梅。两个人讲来讲去，毫不拘束。一个半小时后，雪芝告辞。“\n",
      "在那样一个精神和物质都极度贫瘠的年代，雪芝一个普普通通的售票员，却有着如此丰富的精神世界和审美水准，堪称超凡脱俗。细看两个人的对话，雪芝很“响”，一直在说。阿宝虽“不响”，但他会拿出自己的邮票和字帖与雪芝同看，也会倾听雪芝，懂得她说的每一句话，并恰到好处地回应。两个人一来一往，毫不拘束地一聊就是一个半小时。雪芝为什么喜欢跟阿宝说话？是因为这些话除了阿宝她无人可说，阿宝就是唯一能懂得她的soulmate。\n",
      "阿宝懂得雪芝，得益于思南路多年的家庭教育。而雪芝的精神底蕴，从原著上看，应该来自她的母亲，而不是势利眼的父兄。阿宝在那个年代，遭受了很多伤害和白眼。雪芝各方面的条件要比他好，却毫不计较外在，单纯为了阿宝这个人而真心爱他。雪芝给予阿宝的，除了爱情的甜蜜，更有莫大的安慰与鼓舞，让他重新燃起了对自己的信心和对未来的希望。\n",
      "可是，世事难料，最美好的风花雪月也抵不过残忍的现实，雪芝还是跟着亲戚去了香港。其实雪芝并不情愿分手，临别前主动抱着阿宝，说上她的车永远不要买票。所以78年的阿宝虽然伤心，却坚信雪芝是爱他的。事实也的确如此，不仅雪芝是阿宝的白月光，阿宝也是雪芝的白月光。\n",
      "了解了这些前尘往事，才会明白，1987年的重逢，雪芝对阿宝说的话，对他是怎样的打击。他固执地不相信雪芝能变成这样，甚至连回忆里她的脸，都在蒸汽中模糊起来。直到1993年，当已经成为宝总的阿宝，终于在香港酒店与做服务员的雪芝重逢的时候，才终于了断了折磨他六年的那个执念。却未曾想到，自己有可能因此错失了更加珍贵的东西。\n",
      "变成宝总的阿宝认为，雪芝当初是为了面子，假装自己有钱，并嘲讽自己没钱，所以雪芝一定是爱钱的，正如他自己也是爱钱的。但实际上，雪芝对他的爱，从来都与钱无关，哪怕在物质上，也没有他以为的那么落魄。其实93年香港顶级酒店的服务员，工资远超上海绝大部分的老百姓，更别提13路上的卖票员了。雪芝说“人往高处走”，是真话，她去香港确实没有什么好后悔的。但是从另一个角度上看，雪芝在上海的时候，是个家住“上只角”，每天临帖下棋读外国文学的文艺女青年；到了香港，却只是个被人看不起的内地穷打工妹，每日为了钱辛苦打拼，曾经的那些高雅的爱好和追求，都变成了一无所用的东西。这种精神上的苦闷同样是不足为外人道的。而雪芝越是苦闷，越是怀念阿宝这个soulmate白月光，所以她才会那么多年一直对阿宝念念不忘，哪怕分开十年了，都一定要回来见一面。\n",
      "其实，当年从上海前往香港的很多人，都有雪芝这样的困境。就连有些已经小有名气的作家，到香港后，也在理想与稻粱的矛盾中挣扎。王家卫导演在谈到《花样年华》的周慕云时，专门谈到了这一点。但是，从1987年起就在上海拼命搞钱的阿宝，这一次却无法对雪芝感同身受。他只觉得她生活落魄，爱钱却缺钱，并决定向她伸出援手。两个人的对话是这样的:\n",
      "雪芝:你来香港干什么？\n",
      "阿宝:我来帮服饰公司，谈进口品牌。\n",
      "雪芝:听说你现在做得不错，做进南京路了。老早能到南京路兜一圈，都是大事情了。（注意:阿宝跟雪芝遇到是93年7月，离2月份三羊进南京路只有五个月，但雪芝远在香港，却连这都知道。反观阿宝，87年就有雪芝的名片，知道雪芝所有香港的联系方式，自己亲哥哥就在香港，自己也经常去香港，六年了却对雪芝的境况一无所知。）\n",
      "阿宝:我也没想过。你不是开公司吗？（按说看到雪芝做服务员，他就已经完全明白了。但因为当初被刺激得太深，他一定要亲口问一遍才罢休。）\n",
      "雪芝:开过，但是没成功。运气没你好。（如实以告，真开过公司，但倒闭了。）\n",
      "阿宝:做生意嘛，输输赢赢很正常的。你假使还想做生意，想赚钞票，可以回内地，回上海。现在机会很多。（开始谈钱，开始鼓励雪芝赚钱，在香港开不了公司可以回上海开，上海现在不一样了，有机会赚大钱了。）\n",
      "雪芝:我不回去。回去做啥？再去十三路卖票啊？我跑出来了，就回不去了。（雪芝完全没接阿宝“你要是想做生意……”的茬，明着告诉阿宝自己现在根本不想做生意也不想赚钱。“再去十三路卖票”是给soulmate最后的提示——我可以回去，但不是为了赚钱，是为了和你在一起。）\n",
      "阿宝:现在上海不一样了。（继续谈钱，继续谈做生意，继续鼓励雪芝回上海赚钱，上海现在今非昔比能赚大钱了……）\n",
      "雪芝:你也不一样了。（你对我的心也不一样了，你再也不是当年那个处处懂我的白月光了。）看到你过得好，我为你开心。（我知道你有钱了，成功了，我为你高兴。）人总要赶一头，要么走要么留。唯独不能后悔。后悔没药可救。（这句话可以对照《一代宗师》中宫二的独白:“所谓的大时代，不过就是个选择，或去或留，我选择了留在属于我的年月。” 宝芝二人，雪芝远走香港，心却停留在过去；阿宝留在上海，心却走向了未来。）\n",
      "阿宝:不回去也可以。你待在这里，做我的香港代表。（继续谈钱，继续表示可以帮雪芝赚钱。）\n",
      "雪芝:不用了。你靠你自己，我也靠我自己。否则就没意思了。讲好再看十年，还有四年。还没到下结论的时候。（明确拒绝，我不要你的钱，也不想做你什么劳什子的香港代表，我要的是你的人。我的钱我自己赚。你既然觉得我当年答应十年之约就是要跟你比谁赚的钱多，那我就跟你再比四年好了。）\n",
      "阿宝:那么四年以后，我们九七再见。（注意:87年那次“我们再看十年”，是雪芝先提的；而这次“四年后见”，是阿宝先提的。）\n",
      "雪芝:我们九七见。（那就见吧……反正对我来说，输赢都无所谓了。）\n",
      "雪芝:哎，我问你，你有人了吗？（走后回头问阿宝，这时候雪芝已经决心了断这段感情。）\n",
      "阿宝:我还是一个人，老样子。你呢？（注意：阿宝回答时，低头了。）\n",
      "雪芝:我有了。（知道阿宝还是放不下，但哪怕他还是单身，对自己也没有爱了。于是果断告诉对方，算了吧。雪芝说自己“有人了”是没说实话，阿宝大概也知道她没说实话。）\n",
      "阿宝:蛮好。（造化弄人，缘分尽了，无可奈何。）\n",
      "雪芝:你回去就当今天没碰到我过。（你回去别跟上海的朋友们提起我，也请你忘了我吧——但阿宝回去还是跟陶陶说了，说雪芝成了腰缠万贯的大老板。为了维护她的面子，他编造了一个善意的谎言，但他最在意的还是她有没有钱……）\n",
      "纵观宝芝两人的对话，再比比当年心心相映一起赏梅看字帖的他们，无限唏嘘。六年前阿宝对雪芝说，给我十年，我会证明给你看你是错的。正是他心中对雪芝未泯的爱情，激励他去拼搏奋斗，挣一口气。但是，六年之后，当阿宝提前完成了约定，消除了两人之间所有的物质障碍的时候，当初对雪芝的爱却消失了。不但爱消失了，就连他们曾经那样默契的心，也早已不在同一个频率上跳动了。\n",
      "作为香港顶级酒店的服务员，雪芝见得最多的就是满口是钱的男人。所以当阿宝开口规劝她怎么赚钱的那一刻，她心中的白月光就泯然众人矣了。她知道阿宝单身是为了自己，但也彻底看清楚了，他对他们的感情只剩执念，而她爱的只是一个幻影。所以她主动开口，为两人做了了断——让我们从此各走各路，都不要再执着了。\n",
      "接下来，《随缘》的音乐响起。从后来的字幕中我们知道，阿宝碰到雪芝后，又在香港呆了两个月。但是在这两个月中，他明明知道雪芝在哪里，却一面也没有见她。又过了两个月，雪芝死在了香港，骨灰回了上海，落叶归根。那句“你回去就当今天没碰到过我”，成了她留给阿宝的最后一句话。\n",
      "——\n",
      "PS:《随缘》这首歌，唱的是雪芝，阿宝，小汪三个人。雪芝部分歌词的意思是“失去”；镜头转到哭着在工厂屋顶吃冰棍小汪时，歌词的意思是“承受”。最后两句，镜头又转向了从香港回来的阿宝，他的拉杆箱突然断了，没法轻松地拉着走，便把箱子拎起来，负重前行。\n",
      "投诉\n",
      "© 本文版权归作者 朱碧 所有，任何形式转载请联系作者。 exceed the max sequence length of 126. The exceeded part will be truncated and ignored. You are recommended to split your long text into several sentences within 126 tokens beforehand.\n",
      "2024-08-24 03:17:46 WARNING Input tokens 繁花，我好像是在市井饭桌上知识混子们的谈资中听闻的。浮夸的演技，疯狂的营销，卡司的噱头，沉闷的色调。一句短评“郭敬明在静安区的豪宅里摇晃着红酒杯也不禁放声大笑，你王家卫拍上海也不过如此。” 开头第一集的《友谊地久天长》更不知是不是《小时代》和《繁花》不可告人的巧合。前十集的人物纷至沓来，摇头晃脑不知道在摇头晃脑着什么。中间十集剧情进度飙升，爽剧节奏拉满，误入抖音霸总短剧。直到最后十集，好像王家卫才做回了他自己，繁花中的主角们才做回了他们自己。 繁花是万花筒，是聚宝盆，是老破小，是午夜雨。是千金散尽后的冷暖自知，是满城霓虹下的世态炎凉。我看到了天上，看到了人间，看到了现当代文学庞杂人物的体例，看到了金融市场的脉动，看到了跳跃的数字，看到了洪流中屹立不倒或垂死挣扎的个体，看到了现代主义僵硬套路的故事模板和濒危的真挚情感，看到了集体记忆的情怀炒作，看到了可笑的戏里戏外的消费主义浪潮，看到了对金融大鳄的红色塑造，看到了奔涌的分分秒秒，看到了不能更陈词滥调的现实主义宏大叙事，看到了《花样年华》里的布景灯光，看到了《阿飞正传》里的浪子不回，看到了《重庆森林》里的慢门摄影，看到了《旺角卡门》的商业气息。你可以说繁花是四不像，套着文艺片的面具向烂俗的市场磕头跪拜，也可以说繁花是集大成，黄河路的每一个犄角旮旯都有王家卫的倒影。 所有影子碎片都不可避免地投入历史的苏州河、黄浦江，惶恐或惊喜地在某个必然的节点汇集成汪洋大海，那便是繁花似锦的二十世纪九十年代——横跨上海、深圳、香港和东京的二十世纪九十年代，那便是繁花落尽后的悠长挽歌。 悲剧总是有两种，一种是所有人死亡，一种是所有人活着却不快乐。繁花落尽后的悲剧是第二种。 今夜东方明珠闪耀，春风依旧，维多利亚港沉醉，突如其来的爱情随地下铁逝去，只是主角们和旧时代不复存在，注定成为红绒帷幕后的盛大历史。\n",
      "投诉\n",
      "© 本文版权归作者 月白 所有，任何形式转载请联系作者。 exceed the max sequence length of 126. The exceeded part will be truncated and ignored. You are recommended to split your long text into several sentences within 126 tokens beforehand.\n",
      "2024-08-24 03:17:47 WARNING Input tokens 豆瓣上，《繁花》最多点赞的短评是：王家卫下凡拯救电视剧圈。\n",
      "这可能是近十年来拍得最好的电视剧，有改革开放广阔的大时代背景，有惊心动魄的外贸商战与股市风云，而最动人的是那些起起伏伏的人生故事与细腻的情感纠葛。王家卫极善用镜头捕捉人物情绪，在他的打磨之下，人物刻画丝丝入扣，汪小姐的灵动，李李的笃静，玲子的动静皆宜，阿宝的情义，爷叔的睿智，就连配角卢美琳、小江西、梅萍等也十分出彩。画面、色彩、光影、配乐，都做到了极致。在欣赏美轮美奂的画面同时，虽仍有人诟病剧情的单薄，但我更注重看到那大时代发生的一切，以及每个人的精神成长。\n",
      "人生是痛苦的，爱之不得，又最令人伤心。\n",
      "汪小姐，在排骨年糕店等待那个人的到来。她一边吃，一边回忆，一边笑，但眼里全是泪水。王菲的《执迷不悔》响起，多少无奈与心酸。她知道，一切的痛苦，都来自于对爱的执着。\n",
      "她从晚上7点等到晚上11点，早已超过了约定的8点时间，但“偷心”的人始终没有出现。\n",
      "诸暨事件，汪小姐花光积蓄买车、心急火燎的开车去救阿宝，差点出车祸丢了性命。她见到阿宝没事后的第一反应是：“要是我死了，我就看不到你了！” 看到了吗？她在接近死亡的边缘，说的是“我看不到”，而不是“你看不到”。她的爱是依然执着于自我的需要，这种“我执”也是汪小姐一路痛苦的根源。\n",
      "爱是一种精神上的苦，爱更是无法把握的命运。\n",
      "魏总真的喜欢汪小姐，强总真的喜欢玲子，陶陶真的喜欢小阿嫂，汪小姐玲子真的喜欢宝总，阿宝也真的喜欢雪芝。但，喜欢又能怎么样呢，爱而不得是痛苦，在爱得到之后亦会变得平淡甚至疏离与怨恨。\n",
      "最后，阿宝和汪小姐都遵守了五年的约定，去看了跨年的烟火。但那一刻，他们之间已经隔了一条黄浦江。这是为了阿宝连命都不要的汪小姐，是为了汪小姐连自己后路都不顾的阿宝。可爱情就是这样，差一分一厘，都是空门。\n",
      "也许，世间一切皆有定数，在这一世遇到的人也是早已注定。\n",
      "宝总遇到汪小姐，遇到玲子，遇到李李，仿佛都是无法摆脱的命运剧本。当雪芝最后一次邂逅宝总，让宝总忘了这次相遇后转身离去。那一刻阿宝的心彻底空了，雪芝是他永远的痛，让阿宝今后没有勇气再去爱别人，也给他后来遇到的女人都带来了情感的折磨。人生有时就是这样，再多的努力都敌不过命运的双手。\n",
      "伊壁鸠鲁认为比追逐欲望更高的快乐是静态的精神快乐，最高的幸福就是拥有智慧和友谊，这是减轻人生痛苦的法门。\n",
      "王家卫把李李（辛芷蕾）拍得多美呀，也是我觉得整部剧拍得最美的女人，每一帧画面都凸显李李的优雅大气、聪明自信、胸有成竹。她是在剧中三位女性中唯一与宝总没有感情纠葛的，但为何最后她要救宝总呢，何况阿宝还是在A先生自杀后，进场抄底股票“收尸”的“仇人”。也许，李李把绝境中的宝总投射成投海自杀的A先生，他是她此生的挚爱、精神的导师。那为何宝总又三番四次的帮助李李度过难关呢？或许是友情吧，是同频之间的惺惺相惜。世间上，应该存在伟大的友情。这也是人与人之间的缘份使然，有的人与人之间就是会有天然的吸引。人世间不是只有儿女情长，还有江湖再见的义气。\n",
      "花蕾变成繁花，必须经历一些风霜，才能鲜艳，才能锦绣。\n",
      "汪小姐如果不是经历了与阿宝的分开和组织调查事件，她也不可能断然离开27号外贸大楼独立闯荡。娇弱的她在风雨中搬运货物，在旮旯里的小办公室艰难创业。她要做自己的码头。她千辛万苦去到深圳，找工厂加工外贸单子，宁愿少赚一千万，也不接受宝总的帮助，回身泪中带笑说一句话：为了争一口气。她要完全靠自己，成为那颗闪亮的明珠。\n",
      "玲子如果不是被朋友们讥讽她年纪大与宝总不配，她也许不会远去日本痛定思痛，回来后把曾经承载了那么多心血与美好回忆的夜东京通通砸的粉碎，重新装修营业。她要消除掉宝总留下的所有痕迹、粉碎掉一切幻想，清清爽爽的重新开始自己的独立人生。\n",
      "虽然看起来这些都是外因导致的事件，实则这取决于内心的顿悟与决心。宝总这根刺一直都扎在她们的心里。只有放下执念，领悟到人生遗憾的必然性，才能拔掉这根刺，才能回归平静，找回自我，过独立而清醒的生活。\n",
      "人总会在一些关键的节点，领悟到人生的智慧与成长。\n",
      "纨绔子弟魏总，把与汪小姐合作开公司的开业典礼办成婚礼一般。这个奇葩般的人，也难怪汪小姐不喜欢他。以汪小姐以往的脾性，是绝对不会去加入这场丑剧的。\n",
      "但师傅金花对汪小姐轻轻的说：一个人，所有想的东西，不一定都会来的，在身边的人，有可能不是你最喜欢的，但你要好好珍惜。\n",
      "金花的提醒，让汪小姐明白了，人总是要面对现实的。她接受了一些以往无法接受的东西，出席了开业典礼。她终于突破了自己，脱胎换骨了。\n",
      "但，汪小姐还是拒绝宝总送的新的凯迪拉克，拒绝宝总安排的工厂。这是她保留的最后的倔强，也是对过往的感情的珍视。就如宝总宁愿“得罪”爷叔，导致爷叔离开，也要暗地帮助汪小姐，甚至不惜断了自己的后路。那一刻他们是抛却了理性的，但他们又是那样的真挚可爱。有时候，我们就是会不计后果的坚守心中那一片属于自己的精神领域，就是想任性的做一回真实的自己，甘愿接受命运的任何安排。因为，世间上，没有对错，只有因果。\n",
      "初看不解戏中意，再看已是戏中人。\n",
      "开始觉得汪小姐很吵，看着看着，她那可爱的、傻傻的真心啊，莽莽撞撞，风风火火，在排骨年糕坐着等了一个小时，又一个小时，也等不到那个人。哎，我们谁又不曾做过汪小姐呢？\n",
      "深夜，玲子走在街上，眼泪一层一层的涌出来，她的腰板还是那么直，她的高跟鞋还是那么响亮，她多委屈啊，可她不容许自己低下头。哎，我们谁又不曾做过玲子呢？\n",
      "总是优雅、冷酷又云淡风轻的李李，在看到爱人投海自尽时，她只能把自己锁在车内，任由泪水奔涌，撕心裂肺的喊叫，这是怎样一种痛彻心扉。哎，我们谁又不曾做过李李呢？\n",
      "灯红酒绿，车水马龙的黄河路，总有零落冷清的时刻。霓虹闪烁的至真园转换了门庭，夜东京那热热闹闹饭桌上的好友们也各散东西。曾经叱咤风云的宝总又变回了阿宝，除了一个傻子，已经没有几个人会记得他的名字。\n",
      "繁花再盛，终于也会有平静落寞的一天。\n",
      "在最黑的夜里，却能看到烟火绚烂，冬去春来。\n",
      "人生就是这样，走着走着就散了，走着走着又来了。\n",
      "一边凋零，一边怒放。\n",
      "投诉\n",
      "© 本文版权归作者 沙岗头 所有，任何形式转载请联系作者。 exceed the max sequence length of 126. The exceeded part will be truncated and ignored. You are recommended to split your long text into several sentences within 126 tokens beforehand.\n",
      "2024-08-24 03:17:47 WARNING Input tokens 王家卫的作品，看一部少一部。抱持着这样的心态，在看过他的作品的每一秒每一个镜头，关于摄影、构图、人物小传、两性间的所有若无的心照不宣、来自于人性各种关系的美好和真实，有太多人极尽所能的描写。可能一直以来有坚持听经济相关方面的节目，在看这部剧时没有特别多的无所适从感，每一个人物角色都很饱满立体。 很多人喜欢汪小姐，我认为她还是幸运的，一路有宝总的保驾护航，从创业去抢单子开始，我对她的很多操作都很迷惑，完全无法get。相较之下，更喜欢李李和玲子，喜欢李李的神秘“故事感”，喜欢玲子重新开始的果决和坚韧，每一个人物都好喜欢好喜欢，都能够说得上来喜欢的原因。很幸运，有这样一群人在为他们最爱的家乡留下作品，有这样一位导演不计时间不计成本拍摄一部上海九十年代形形色色的人和故事的缩影。\n",
      "投诉\n",
      "© 本文版权归作者 水瓶缺个瓶 所有，任何形式转载请联系作者。 exceed the max sequence length of 126. The exceeded part will be truncated and ignored. You are recommended to split your long text into several sentences within 126 tokens beforehand.\n",
      "2024-08-24 03:17:47 WARNING Input tokens 刚看完，心情久久不能平复。 结尾还是政治正确的大团圆结局：李李帮A先生还完债自首了，强总被抓了，宝总退出股票市场，汪小姐和玲子生意都节节高…看的时候我就在想，或许只有这样的结尾才能过审吧！如果放在现实中，我猜或许宝总在最后会被强总打得很惨，强总越做越大越做越强升职加薪，李李用赚到的钱享受余生，汪小姐和玲子也会在一路上边解决困难才一步步成功，而不是一下子就这么顺利吧！ 剧情看到一半时我就想，为什么这部剧的名字叫《繁花》呢，看起来好像是宝总和几个女人的故事，但明明剧中的所有女性都是那么的鲜活和富有生命力：玲子能干有想法还有领导力，汪小姐积极乐观勇敢不怕困难，李李理智有头脑还很果敢，敏敏可爱坚强更像是我们普通的大多数人的缩影，还有不信命勇敢的小江西…这部剧中的男性好像分明就是这几个女性的配角，为了凸显她们各自的个性而存在的。繁花繁花——繁，很多，花，坚强美丽的女性！这就是一部女性的群像戏。\n",
      "说回剧本身，一开始自己最喜欢爷叔，羡慕宝总身边能有如此睿智、理性能一直帮他兜底和指引他的人，佩服爷叔的眼光和全局观。越往后看越喜欢剧中几乎每一个人，他们一个个似乎就是我们身边人的缩影。\n",
      "对魏总由一开始的厌烦到最后才发现他所做的一切均源于对汪小姐的喜欢，没想到竟然是一个恋爱脑；范总一开始的啰啰嗦嗦，到最后他的正直和真诚，也越来越喜欢他。\n",
      "爷叔最后对汪小姐的做法，突然对他的评价一下子降低了，但代入后换位思考了一下瞬间就理解他了：他可是那个帮宝总兜底的人，他要做的，是能够帮宝总出谋划策，不会亏损，让他这个先锋可以去做自己想做的事情。如果在现实生活中，谁又做得到像宝总那样，面对自己的竞争对手，在自己都泥菩萨过江自身难保时，在有人抢自己生意时，一次次将自己的生意和钱拱手相让，一次次地帮助对方，我猜很少有人能够这么做得到吧！\n",
      "越写越不知道在说些什么说到哪儿了，这部剧是值得反复重刷的，太好看了！\n",
      "投诉 exceed the max sequence length of 126. The exceeded part will be truncated and ignored. You are recommended to split your long text into several sentences within 126 tokens beforehand.\n",
      "2024-08-24 03:17:47 WARNING Input tokens 一、\n",
      "天心不许人意，只要一个疏慢，就有果报。\n",
      "二、\n",
      "小而精，大而全\n",
      "日清月结，利析秋毫。\n",
      "外行看门面，内行看后门。\n",
      "愿君多珍重，山水有相逢。\n",
      "一切尚未定义，一切皆有可能。\n",
      "年年月月花相似，岁岁年年人不同。\n",
      "唱戏不如听戏好，上台终有下台时。\n",
      "来如春梦不多时，去似朝云无觅处。\n",
      "三、\n",
      "不讲道理、不懂规矩、没有礼貌\n",
      "用心，用情，用力，做好工作\n",
      "花无百日红，不时，不地，不食，最好的时光，就在眼前，就在当下。\n",
      "开好一家店：有主张，搞得定，摆得平，最后还有一点，要输得起\n",
      "四、\n",
      "山雨欲来风满楼。\n",
      "我们要感谢这个时代。\n",
      "只有看到未来，才会有未来。\n",
      "箭在弦上，别无选择，只能向前。\n",
      "因为感情而背叛交情，走到哪里，都是不被原谅的。\n",
      "顾客永远是对的，因为路是人走出来的，有人才有路。\n",
      "目标从来都不遥远，一步步，一天天，只管全力以赴，剩下的交给时间。\n",
      "别人只看结果，吸取教训的只有你自己\n",
      "能改的我肯定努力改，要是改不掉的，我也已经意识到了，我相信凭我认真的态度，肯定没问题的。\n",
      "乐观是好的，最坏的打算还是要做的，什么事情都要未雨绸缪。\n",
      "五、\n",
      "没有南京路，就没有上海的十里洋场，孙中山先生要到南京路配眼镜，卓别林到南京路定真丝衬衫，爱因斯坦在南京路演说相对论。人以物显，物以人名。好比，去纽约要去第五大道，到巴黎要逛香榭丽舍，每个外地人到了上海，总归要去逛逛南京路，因为那里是“中华第一商业街”。\n",
      "时代的列车全速前进，带来前所未见的风景，也将一幕幕人间聚散抛在身后，一代人有一代人的使命，没有人可以独善其身，忙碌是遗憾的借口，明天又是新的一天。\n",
      "人生是一场荒凉的旅行，烟花背后每个人都有自己的故事，沧海桑田是缘、是劫、也是宿命，\n",
      "空门是生意场，也是人生路；是天注定，也是没得选，如果念念不忘必有回响 是一种必然，那么阴差阳错、失之交臂也可能是另一种必然。\n",
      "投诉 exceed the max sequence length of 126. The exceeded part will be truncated and ignored. You are recommended to split your long text into several sentences within 126 tokens beforehand.\n",
      "2024-08-24 03:17:47 WARNING Input tokens 《繁花》以改革开放四十年的上海为背景，通过描述一群普通人的生活变迁，展现了这座城市的发展历程。既有时代的烙印，也有个人的抉择。作品以独特的叙事风格，描绘了一个繁华与衰败、理想与现实交织的世界，让观众感受到岁月流转中的悲欢离合。\n",
      "剧情张弛有度，悬念迭起。编剧巧妙地将时代背景与个人命运交织在一起，让观众在感受时代变迁的同时，也能关注到人物的成长。剧中多个剧情转折都处理得相当出色，让人瞠目结舌。例如，李李与阿宝的感情波折，以及他们在人生道路上所经历的种种挫折，都让观众为之动容。这些情节设置不仅展现了人物的坚韧性格，也传递出对生活的热爱和执着。\n",
      "该剧深刻地反映了改革开放四十年来，我国在社会、经济、人文等方面的巨大变革。作品通过展现李李和阿宝这一代人的人生历程，探讨了人性、道德、亲情、友情等诸多方面的问题。在现实生活中，我们也面临着类似的抉择，如何在变革中坚守初心，如何在物欲横流的社会中保持纯洁的心灵，这些问题都值得我们深思。\n",
      "《繁花》在摄影、音乐、剪辑等方面都有着极高的艺术水准。摄影以独特的视角捕捉了上海的韵味，展现了这座城市的繁华与衰败。音乐深入人心，为剧情增色添彩。剪辑上，作品节奏紧凑，让人回味无穷。这些艺术呈现使得《繁花》具有极高的观赏价值。\n",
      "总体来说，它是一部高品质的电视剧，它以真挚的情感、饱满的人物、深刻的话题赢得了观众的喜爱。作品既展现了改革开放四十年的时代画卷，也传递出了人性的光辉。在表演、剧情、主题、艺术表现等方面，《繁花》都堪称佳作。这部剧让我们感受到了生活的繁花似锦，也让我们在繁华中看到了真实的人性。\n",
      "投诉 exceed the max sequence length of 126. The exceeded part will be truncated and ignored. You are recommended to split your long text into several sentences within 126 tokens beforehand.\n",
      "2024-08-24 03:17:48 WARNING Input tokens 日前，电视剧《繁花》完结，男主阿宝经历商场尔虞我诈的考验，最后顺利脱身，让观众随其跌宕起伏的经历为主角松了一口气。\n",
      "在事业线之外，阿宝的情场际遇留给观众不小的遗憾。阿宝\"人从花丛过，万花不沾身\"。阿宝身边有各种爱他、宠他、愿意跟随他的女性，他也乐于与不同女性保持亲密关系，可到了对方要与阿宝确定关系时，他会沉默、保持距离，拒绝回应。\n",
      "现实中，有些女性也为像阿宝这样的男性黯然神伤，到底为什么有些男人对女性的态度总是暧昧不清，没有办法明确表态？做不到明确拒绝，让对方死心；也做不到忠于一位伴侣，不让身边人留下遗憾呢？\n",
      "§ 暧昧的心理\n",
      "从中性的角度来看，而非负面的角度，\"暧昧\"是人际交往的一种形态，也仅仅只是一种形态。每一种人际交往的形态，都展现出一个人他看待关系的观点，这个观点来自他的成长历程、交往经验等等。这不能简单用\"好\"、\"坏\"的道德判断，加以抬高或贬低任何一种模式。\n",
      "要简单用\"渣\"、\"海王\"、\"绿茶\"之类的语言去指责搞暧昧的人，或许简化了我们对于一个人的认识。就像在我们不了解一个人的背景，以及经历的情况下，就批判一个人是好人或坏人，都蕴含着\"我比别人好\"，一种把自己拔高，同时把他人降格的心理。\n",
      "众多相关的心理学理论中，我以为和暧昧最相关的，就是\"依附理论\"。\n",
      "按学者巴瑟洛缪（Kim Bartholomew）和霍罗维茨（Leonard M. Horowitz）的研究，他们从一个人看待其\"自我\"和\"他人\"的不同态度，是\"正面\"，还是\"负面\"，组合推演出四种亲密关系的人际模式。\n",
      "这四种模式分别为：\n",
      "A. 安全型（Secure）\n",
      "这类型的人能同时用\"正面\"的态度看待自我与他人的关系。\n",
      "他们对自己有比较真实的认知，能接纳自我的不完美，同时，他们能用同样的心态看待与他人之间的关系。即使发生冲突与不快，他们也能怀抱希望和乐观的态度，去扮演对人际关系产生正面影响的角色。\n",
      "比如一位对关系的心理属于安全依附的人，当他和别人吵架，别人说\"你烂透了\"、\"你很糟糕!\"，他可能当下会心理动荡，但过一阵子，他的心态就会恢复。因为他对自己是有自信的，他的自我是稳固的，他人的言语攻击，不至于撼动他对自己的根本理解。\n",
      "这样的人，也比较不容易在关系中掉入PUA的陷阱，或者失去自我，因为他的自我很稳固。\n",
      "相反地，自我不稳固的人面对这样的人，可能会受挫。比如后面我们谈到的焦虑依附型，某些人太喜欢测试他人是否爱自己，但对于自我稳固的人，他会反思这段关系中的自我，那么他很可能会放弃这段有损自我的关系。\n",
      "B. 焦虑依附型（Preoccupied）\n",
      "这类型的人多用\"正面\"看待与他人的关系，同时惯于用\"负面\"的角度看待自己。\n",
      "可以说，他们看待自我与他人的关系是不平等的，很容易在人际交往中处于一种悲观的心态，认为自己\"不够好\"，处于随时可能被他人批评、抛弃的焦虑情绪中。自然，他们也很容易在亲密关系中自责。\n",
      "C. 疏离型（Dismissing）\n",
      "这类型的人多用\"正面\"心态看待与自己相处的时刻，同时倾向于用\"负面\"的评价来看待与他人的关系，仿佛在他们眼中，与他人相处的好处永远比不上独处。\n",
      "比如日剧《不结婚的男人》中的男主就是这种心态，他认为一个人的幸福感远超恋爱和婚姻生活，所以选择单身。\n",
      "对一般人来说，分辨这两种不同依附心理的对象至关重要，有些人把\"疏离型\"当成\"焦虑依附型\"，以为靠自己的努力可以化解对方的婚恋观，好进入婚姻或更具有缔约性质的关系。这种努力基本是无效的，因为对方根本不是因为焦虑而不敢结婚或恋爱，他们只是觉得\"一个人比两个人更好!\"\n",
      "误把\"焦虑依附型\"心理的人视为疏离型，也会造成误会，影响关系。因为焦虑依附型的人其实内心\"非常渴望连结\"，他们只是因为焦虑而做不到，忍不住试探，甚至有时因为被自己绝望的幻想吓到，宁愿提前结束关系。\n",
      "所以我们会发现，有些焦虑依附型的人，明明是他（她）主动提分手，却也是他（她）在分手后不断试图回头联系，或要求复合。\n",
      "真正疏离型的人，他们分手会分得很干脆，因为分手对他们来说是过得更幸福。\n",
      "不像焦虑依附型，他们分手只是想从自己的焦虑中喘口气，他们很可能十分喜爱身边的伴侣，并且非常需要对方给予温暖，只是他对于\"被抛弃\"等受伤的恐惧想象，致使他展现出各种令人不适或捉摸不定的言行。\n",
      "D. 恐惧依附型（Fearful）\n",
      "这类型的人看待自我与他人的心态都是\"负面\"的、消极的、低评价的。他们对人际关系没有好感，也不抱什么希望。他们太害怕了，害怕与人交往，却又不知如何与自己独处。\n",
      "我们会发现，某些人一个人的时候过得不好，和其他人在一起也好不到哪里去，他们无时无刻不处于一种心理消耗的状态。\n",
      "这类人需要帮助，因为对他们来说，整个人际交往的环境，乃至于整个社会都是不安全的。但一个人无法脱离社会生存，长期处在恐惧中可能造成不可逆的心理疾病，影响生活的幸福感。\n",
      "§ 宝总的底色是阿宝，阿宝的底色又是......\n",
      "回头分析阿宝这样的男人，他在与雪芝你侬我侬的时候，处于安全依附的状态。当雪芝抛弃他之后，他企图证明自己\"我也能成功\"，这时他处于焦虑依附的状态。\n",
      "他努力的动力来自\"我不够好\"的焦虑，所以我们在剧中看到，他事业很成功，却每天都得吃安眠药才能入睡。对他来说，雪芝留下的创伤使得他看待外在关系，总觉得\"不稳固\"；同时看待自己又担心\"我不够好，会被抛弃\"，双重焦虑下，一个稳固的关系总隐藏着破裂与消解的风险，那么暧昧不明反倒让他的心理压力小一些。\n",
      "阿宝不属于恐惧依附型，因为他对人是有信心的，只是对自己没信心。比如他很信任爷叔、汪小姐等人，相信他们会帮助自己。可是他对自己没有信心，所以接受他人的帮助，他内心始终有\"亏欠感\"，这也是为什么他总是急于回报他人，因为他总觉得\"我那么糟糕，别人对我好，那是我欠别人的。\"\n",
      "安全依附心理的人就没有这样的感受，别人对他好，他欣然接受，不会总有亏欠感。\n",
      "阿宝也不属于疏离型，因为他并不享受一个人的生活，他只是没有自信能满足别人的期待。\n",
      "谈到这里，或许我们可以定义\"暧昧\"背后的心理，其实就是一种\"焦虑\"依附的状态。\n",
      "阿宝总是站在一个\"我比你好，我来拯救你\"的高度，但这个高度只是表面上凌驾于对方，实际上，宝总的底色是阿宝，是那个被雪芝抛弃的阿宝，是那个败给钞票的阿宝。即使他事业成功，也没有建立起内心真正的安全感。\n",
      "真正的安全感不再于拥有多少，而在于\"即使我失去了那些外在的社会符号，我仍知道我是谁\"的稳固自我。\n",
      "因此，暧昧者往往无法给予对方承诺，因为他们没有实现承诺的自信。即使表面上在关系中处于主动位置，比如社会地位、财富等条件比对方好，他也无法有效转化为自信。因此，要暧昧的人做出决定是十分困难的，他们没办法过自己那一关。\n",
      "§ 如何与焦虑依附的人相处？\n",
      "在我们澄清焦虑背后的心理上，面对焦虑依附的人就显得没那么抽象了。焦虑依附的人，他们对自己没信心，对关系缺乏安全感。面对暧昧，就是在面对这样一个人。\n",
      "在我看来，我们没有必要非得和这样的人建立多么亲密的关系，但如果你非这么做不可，下面有几条建议，或可帮你更加从容地面对。\n",
      "首先、守护自己的安全感\n",
      "由于我们面对的是一位缺乏安全感的人，有时会使我们也不禁怀疑对自己的自信、对关系的信心产生怀疑。所以我们要告诉自己，我们面对的人，他的不安全感并非来自于我们，避免卷入。\n",
      "其次、真诚做自己\n",
      "当你越是真诚地做你自己，其实对焦虑依附的人来说，他眼中的你\"越稳定\"。对焦虑的人来说，生活的变数越少，他越不容易焦虑。（但有时焦虑依附的人会有一厢情愿的想法，比如欺骗自己\"一切永远不变\"。）\n",
      "第三、减少让对方做选择题的机会\n",
      "由于焦虑依附的人喜欢以逃避的态度处理关系，如果今天我们对对方提要求，寻求答案，我们给他们\"太多选择\"，只会让他们更加不知道该怎么选。所以当我们需要对方做什么，最好的方式就是\"告诉对方，我希望他怎么做\"。让对方只要考虑\"做或不做\"就好，降低他可以逃避的空间。\n",
      "最后、拒绝\"交易式\"相处模式\n",
      "当暧昧对象试图通过其他方式寻求你的原谅，留住你。比如他不愿意确定关系，却想通过礼物等方式避免关系破裂。你需要明确拒绝，否则会让关系变成一场交易，他通过交易心安，而你也把自己变成他可以通过某种\"代币\"控制的东西，这样的关系往往只是延长痛苦，而非增加幸福。\n",
      "当我们希望关系进入稳定的下个阶段，而对方确实无法满足我们时。相较之下，找个和自己志趣相投，具有安全依附心理的人，是结束自我折磨的好方式。\n",
      "§ 结语：每个人都有他的故事，而每个人也有不受伤的权利\n",
      "每个人的模式背后，往往都有一个不为人知的故事。比如《繁花》中的阿宝，他之所以没办法开启新一段亲密关系，在于他曾经有过一段苦恋，那段苦恋带来的痛苦，在多年后仍使他伤痛。\n",
      "也许我们会同情阿宝这样的人，但同情之余，别忘了我们也有我们被爱、被关心，在稳固的关系中得到安全感的权利。\n",
      "我们生来都不是谁的救世主，对于无法共创美好，相处宛如折磨的关系，当断就断有时是不得不，却也是最好的选择。\n",
      "就像咨询的起点，是一个人愿意进入咨访关系的求助意识。没有谁能拯救谁，只有当一个人自己愿意改变，愿意接受帮助，他人的帮助才有意义，也才能使得上力。\n",
      "你说阿宝懂不懂这个道理？我以为他懂的，只是他还没准备好，而在他准备好之前，汪小姐也好、玲子也好、李李也好，她们的出现，注定只是错过。\n",
      "作者：高浩容。哲学博士，台湾哲学咨商学会监事。著有《小脑袋装的大哲学》、《写给孩子的哲学思维启蒙书》等著作。公众号：\"容我说\"。\n",
      "投诉\n",
      "© 本文版权归作者 高浩容 所有，任何形式转载请联系作者。 exceed the max sequence length of 126. The exceeded part will be truncated and ignored. You are recommended to split your long text into several sentences within 126 tokens beforehand.\n",
      "2024-08-24 03:17:48 WARNING Input tokens 《繁花》中的小人物，对丈夫过于紧张又忧又惧又怕失去的芳芳终于生下孩子而丈夫也放下执念回归。玲子放下对宝总的执念自己做老板娘，小冮西受卢美琳一巴掌决断恩怨和另两个小伙伴一起开店。范总在阳光中欢快地挥着手，喊江湖再见。\n",
      "贪小便宜又重情重义的玲子可以不必象其他国产剧一样全身心为男人付出一毛不要在男人不需要她时自己找一个堂皇的理由退出，黯然收场。做小三的小江西在受卢美琳一巴掌后也是全身而退。国产剧中可是要再做小三再被人抛弃，凄惨下场。\n",
      "而暗算过汪小姐的梅萍，亦离开七十六号自立门户。见到宝总时也坦然面对了自己和汪小姐的一如坐电梯和走楼梯的差距，对汪小姐的羡慕和妒嫉。梅萍最终坦然地走向楼梯，就如普通无依靠的所有普通人一样，对坐电梯的曾经羡慕过妒嫉过最终放下坦然地一步一步地走自己的楼梯。\n",
      "普通人不必成为任何人的踏脚石，不必为任何人奉献一生心血无所得还自我感动，普通人可以犯错，可以贪小便宜，可以羡慕，可以妒嫉他人也可以放下执念放过自己。\n",
      "愿最终所有人都可以在阳光下挥手，然后江湖再见\n",
      "投诉 exceed the max sequence length of 126. The exceeded part will be truncated and ignored. You are recommended to split your long text into several sentences within 126 tokens beforehand.\n",
      "2024-08-24 03:17:48 WARNING Input tokens 我来评价一下哈哈，不咋看电视剧，才疏学浅，应该有一些纰漏，见谅，若能指正，不胜感激。个人感觉本剧最大的问题就是画面略显单调。\n",
      "有人说这部电视剧有电影的质感，的确，剧中强烈的光影效果塑造了很强的氛围感。但我有几个感受，画面大部分背景虚化，交代不出环境，我猜测绝大部分观众看完之后可能都摸不清房间或者街道的空间布局。同时人物大部分都是拍到胸像，然后过肩镜头跳来跳去，你一句我一句，通过对话来推动剧情，剧中通篇都是这样相似的场景略显单调。不过这样的话就少有大场面的画面，是不是能省下不少经费哈哈。\n",
      "再加之反复重复的背景旋律，用一两次能很好烘托氛围，让人入戏，结果一直在用，就又显得单调了。另外，剧中也有很多精致的小画面，但是个人感觉这种细致的画面，和独特的剪辑技法，加上强烈的光影效果，所打造的电影感并不适合在一个长达30集的电视剧里反复展现出来。相对而言，我更喜欢表现手法多样化一点的。\n",
      "投诉\n",
      "© 本文版权归作者 Jinpo 所有，任何形式转载请联系作者。 exceed the max sequence length of 126. The exceeded part will be truncated and ignored. You are recommended to split your long text into several sentences within 126 tokens beforehand.\n",
      "2024-08-24 03:17:48 WARNING Input tokens 总算看完了，MV拍的挺好，光影摇曳，有些怀旧老物件，上海话生动亲切，用上海话讲花样年华的台词沪籍演员们不容易，感觉得到是陪香港阿叔白相相。\n",
      "30集大概讲了这么几件事，从内地人角度看哈：\n",
      "主角上海青工，大约55-58年生人，在解放后公私合并后出生，祖父是资本家，那时候大概在工商联合会里已经没啥花头，主角所以小时候算卢湾区上只角人，但家境已经很平常了而且成分不算好，文革中后期中学毕业没办法上大学，不用上山下乡，进厂当了青工，文革后78年谈了一个对象是公交车售票员，谈了一两年售票员家来了香港亲戚，女的移民去香港了。\n",
      "又过了一两年主角青工自己文革前赴港的失联亲哥也联系上了，主角离开工厂，准备开始自己做生意，认识一个之前外贸公司干过的老工商，犯了一些经济错误刚从提篮桥出来，主角就去找这个老法师爷叔当智囊，刚好国内股票证券市场开始，借了胖友的讨老婆铜钿炒股成功，有了资本积累，靠香港亲阿哥关系搞了个港商代表的身份准备开始做做外贸，按当时政策外贸采购都要从上海外贸公司走单。主角费力气搭上一个刚从上外毕业年轻外贸员，做服装加工外贸生意。慢慢有点名气。\n",
      "93年初主角被汽车撞伤，肇事司机是以前一个炒股胖友的楞头儿子，他爹炒股失败死掉儿子误会是主角害的就来报复，主角痊愈后没追究这儿子责任，继续做外贸。\n",
      "有个杭州集体企业针织厂做了一批T恤用了新的针织面料技术，老销售科长来上海找承销，主角和外贸小姑娘看他货色不错给他搞了一个上海外贸贴牌的商标（当年上海外贸拿江浙沪轻工集体企业的产品经常会有个注册商标，其实是一种代工委托方式以便控制销售链）这一来实际是为了转内销，在上海百货大楼上柜卖出一些名声。由于和主角合作业绩名气比较大，外贸员小姑娘被同事嫉妒举报有经济受贿嫌疑，停职下放仓库劳动并接受调查，最终发现是一些搞七捻三的误会。小姑娘洗清冤屈后就停薪留职下海了，当时也是92南巡后的国资公司职员下海浪潮。那么刚好是快94年。\n",
      "这个导致女外贸员被停职调查的搞七捻三的误会，主要来自主角的暧昧女朋友，是主角在日本商务出差时认识的一个东京银座夜总会上海籍女招待，帮了小忙，做生意的人感念吉利就在上海弄了个小店面邀请这个女招待来经营，从年龄算女招待大约比主角略年长两三岁最多，但主角一直和女招待暧昧也没想认真轧朋友。这边女招待也有点邪气百出，把他当金主，经常在主角身上揩油弄点小钱。女外贸的受贿乌龙就是这么搞出来的，其实就是怂恿男主给女外贸送了一对不值钱的耳环，女招待骗男主花了高价，男主睁一只眼闭一只眼没说破，结果女外贸在单位就说不清了。\n",
      "这点小误会解释清楚后女招待也死心了，自己重新融资认真做餐饮店生意，因为女外贸自己下海开公司变成了竞争对手，所以男主角在外贸赛道上开始躺平摆烂，回归到炒股或者说资本市场，一顿皮条客操作帮上海服饰公司拿下上市资格，并作为股票一级市场上的资金和深圳来的一个炒股团（早期借壳国资背景的基金机构）对飙做股票割散户韭菜，最后被深圳人逼得险些平仓变成脱底茶箩，最后关头拿家底和上海另一个炒股团换了浦东川沙的一块地的使用权，主角和之前撞他的股票老朋友儿子一起经营土地，这个约莫就是94年上半年。\n",
      "电视剧故事就结束了，主线就是93年到94年上半年，其中还有穿插一个饭店女老板娘的小片段，这个女饭店老板娘原来是和深圳炒股团有渊源的女股票交易员，炒股团前老大的情妇，前老大爆仓自杀后卷款改名换姓到上海黄河路饭馆一条街开个饭店主打商务宴请，顺带做做信息掮客，和主角有些生意交往，但捋一捋情节发现在主线情节里女交易员戏份其实可以忽略，无非就是个通风报信的点缀角色，主要是给MV加点氛围感的。\n",
      "这样再不断回忆插叙，一共水了30集，并且每个人物杀青情节都在深情缅怀这一年多的沧海桑田啊我们江湖再见了————仿佛上海的1993年好像是雨果写的巴黎1793年。\n",
      "这个故事后面可以这么编———主角退隐江湖后杭州针织厂老销售科长也退休了，但外贸订单供应市场，B2B外贸采购在江浙沪这种传统轻工业基地非常适合，随着市场经济和企业制度改革，进入轻工外贸的黄金期。那个杭州老科长认识当地一个曲艺老演员，经常一起喝喝茶，曲艺老汉有个儿子从师范毕业不安心当老师，看准这个市场，老科长介绍他和归隐的主角取取经，主角启发这个师范毕业生就做了个叫“中国黄页”的公司。炒股胖友中有个帮主角团买买纸烟的小赤佬，刚刚中学毕业从宁波来上海跟班，后来慢慢接手私募操盘，直到某天开车刚下跨海大桥被警察拦住带走。跟着主角种地的川沙儿子在浦东开发中把土地使用权换了房地产开发公司的股份，和主角一起再次套现。女外贸和海宁小老板开外贸皮包公司，吵吵闹闹一起做生意起起落落结婚离婚，过了10年也没小孩，女外贸一个人回到上海在朋友外贸公司继续做白领打工。刚好海宁小老板有个外甥从浙大毕业出国又回国在上海创业，海宁老板拜托前妻稍微照顾一下这个小孩，女外贸帮着给在长宁区找了个地方开公司，鼓励这小孩也做消费品市场。到2020年春天遇到新冠疫情，女外贸正式退休。黄浦江边遇到了戴口罩散步的男主角，也到了老法师阿叔的年龄…………香港回归也20多年了要么回忆青春，两人凑点余钱就找了个香港导演投资拍个电视剧吧回忆93、94年。电视剧播出时长宁区创业的小公司已经进军美国消费品市场，中国轻工业消费品从欧美供应链末端杀到终端零售低价席卷….不过电视剧请的香港导演说好了围绕93年，最多插播1997年往后故事他不拍的，反正和我主角也关系不大了。\n",
      "投诉 exceed the max sequence length of 126. The exceeded part will be truncated and ignored. You are recommended to split your long text into several sentences within 126 tokens beforehand.\n",
      "2024-08-24 03:17:48 WARNING Input tokens 《繁花》10，看多剧中的高光时刻，想到陶陶，卢美琳和菱红，也许像她们这样玻璃渣里找糖，不完美人生才是常态。\n",
      "《繁花》，有多少高光时刻，就有多少冷暖自知，低处行路时刻。\n",
      "一辈子渴望自由的陶陶，兜兜转转，回到鸡飞狗跳日常生活。\n",
      "心高气傲卢美琳，经营半辈子餐厅，最后人财两失，被迫远离黄河路。\n",
      "总爱依赖身边人，收获一些好处的菱红，最终一无所有闯荡北京。\n",
      "他们也想过主动把握自己的人生。\n",
      "他们或许才是我们在生活中经常遇见，看似失败却也曾精彩活着的人。\n",
      "1，贪玩陶陶，最终选择回家情愿不自由\n",
      "有爷叔加持的宝总，有个赤膊兄弟陶陶。\n",
      "宝总当初找到爷叔后，好像刘备有了辅佐他一路飞升的诸葛军师。\n",
      "如果当年是陶陶去找爷叔，会有这样的结果吗？\n",
      "这个很难说，毕竟陶陶没有宝总的经营头脑，似乎也没有对改变命运的执着。\n",
      "尽管他和宝总一样重情重义，还有颗追求自由的心。\n",
      "宝总渴望自由，是因当初为情所伤。陶陶呢，则是太早进入婚姻，像还没看过世界的鸟，就折翅关在笼子里。\n",
      "他不甘心。\n",
      "当他眼见曾借过第一笔钱的兄弟，财富飞升，他真心祝福，并不羡慕。\n",
      "他羡慕，宝总万花丛中过，片叶不沾身。\n",
      "未婚宝总身边有亲人般玲子，好搭档汪小姐，还有红颜李李，已婚陶陶身边只有彪悍妻子芳妹，他想搭风情小阿嫂，却有贼心没贼胆。\n",
      "最后，他放弃自由的幻梦，和刚刚生了孩子的妻子抱头痛哭。\n",
      "陶陶像不像我们大多数人，总想改变命运，却没有辉煌雄心，也没有拒绝诱惑的勇气。\n",
      "甚至没有改变现状的行动，最后只能过最平常的小日子。\n",
      "可是相比宝总跌宕商战人生，身边人一个个离开，孤家寡人活着。\n",
      "陶陶像渴望飞翔的鸟，最后归巢至少有人在等候。这种不完美的平常生活，未尝不是一种烟火幸福。\n",
      "2 好胜势利卢美琳，人财两空离开黄河路\n",
      "卢美琳刚出场时，真是一副令人生厌的嘴脸。\n",
      "你瞧她，这边客气吆喝范老板光顾，看他要去新开饭店，立即变脸。\n",
      "再看她拉帮结派，张扬跋扈。\n",
      "聚集黄河路上的老板娘，用尽拉电闸，买通厨师长和断供应商不光明手段。\n",
      "又见她听到离开外贸大楼的汪小姐要订餐，势利不给订包房。\n",
      "势利排外，吃相难看，为生意不择手段。\n",
      "这样的卢美琳，够让人烦吧？\n",
      "可就是这样一个不择手段的老板娘，也有她的真心人伤心处。\n",
      "曾经的卢美琳也是一个简单快乐的人，当她依靠的青梅竹马忽因犯事被关进监狱，留她一人面对讨债人。\n",
      "她的人生信条变成不信别人，一切靠自己，张牙舞爪活下去。\n",
      "于是她变成了我们看见的样子。\n",
      "丈夫是一个浑浑噩噩，整日里赌博搞事情的小白脸。餐厅全靠卢美琳一人勉力维持。\n",
      "为了在黄河路上维持红火生意，她像护着自己孩子的母熊一样彪悍。\n",
      "只有面对愧对她的前男友杜红根，她才流露脆弱的一面。\n",
      "当卢美琳学着接受现实，再累也和扶不上墙的丈夫将就过。\n",
      "没想到命运不放过她，赌鬼丈夫败掉餐厅，躲债摔死。\n",
      "卢美琳离开黄河路，杜红根来接她。她从车窗看灯红酒绿的黄河路，仿佛一场梦。\n",
      "也许，我们中也有人，用尽全力，只想让自己过得好一点，最后没有得偿所愿，几乎失去了一切。\n",
      "可是，幸运的，我们身边还有家人爱人，再不济，我们还有健康。\n",
      "这样的我们，也还可以好好活着，就算不能东山再起，也无愧此生。\n",
      "3 依赖他人的菱红，一无所有闯北京\n",
      "菱红就像卢美琳的另一面，她最初选择的人生是依赖他人。\n",
      "在东京的时候，先依赖丈夫，后靠玲子帮忙。\n",
      "回到上海，开着精品店，却还是靠玲子背后的宝总撑台面。\n",
      "她不想过太辛苦的人生，更愿和强大的人绑定在一起。\n",
      "就像是攀援的植物。\n",
      "直到有一天，她依赖的朋友玲子变成另一个人。\n",
      "一个不依赖他人，活出真切自我的老板娘。\n",
      "菱红像激发了内心的火种，她是不是也可以不再攀援？\n",
      "于是，她决定到一个全新的地方独自闯荡。\n",
      "我们当中，是不是也有些人，懒得去改变，忽然因为一件事的震动，发现自己原来也可以靠自己好好活一回。\n",
      "人到中年，一无所有重活一回的菱红。\n",
      "和追求改变，却困在命运里的卢美琳不太一样。\n",
      "菱红更像是从命运寻找新出口，外弱内强的人。\n",
      "我们当中，是不是也有像菱红这样的人，人到中年，才发现还没真正活过，重新开始未知的人生。\n",
      "写在后面\n",
      "谁不是，看别人热闹非凡，看自己一地鸡毛。\n",
      "这或许是我们不甘的原因。\n",
      "陶陶、卢美琳和菱红们，回头看看自己的人生。\n",
      "回归、接纳、重启，他们的人生其实和宝总玲子一样，面临着人生课题。\n",
      "看似平常的日子，我们都是自己每段人生的主角，不完美人生也可以玻璃渣找糖吃。\n",
      "本文原创，图片为网络精选\n",
      "@怡话书影，探秘城市，沉浸书影\n",
      "投诉\n",
      "© 本文版权归作者 怡儿话书影 所有，任何形式转载请联系作者。 exceed the max sequence length of 126. The exceeded part will be truncated and ignored. You are recommended to split your long text into several sentences within 126 tokens beforehand.\n",
      "2024-08-24 03:17:48 WARNING Input tokens 尤其是倒数几集 有个镜头李李和宝总在楼梯上的谈话 李李转过来那一刹那 整个转身动作外加配乐显得十分造作 急 显得十分急 虽然王家卫走不出2046和花样年华 但繁花拍的还是很唯美 很夸张 场景搭建也很节省成本\n",
      "最后想说小江西的戏不错 哭戏戏薄 戏不过\n",
      "写这么多我就是为了凑140个字 之后可以发出\n",
      "投诉\n",
      "© 本文版权归作者 william 所有，任何形式转载请联系作者。 exceed the max sequence length of 126. The exceeded part will be truncated and ignored. You are recommended to split your long text into several sentences within 126 tokens beforehand.\n",
      "2024-08-24 03:17:49 WARNING Input tokens 看了电视剧繁花之后，读了小说原著。电视剧版本和小说版本讲的完全是两回事，电视剧里每个人都繁花似锦，小说里除了阿宝都繁花凋零。 作者讲他的初衷是宁繁毋略，宁下毋高，书里也确实是这样繁：全是鸡毛蒜皮家长里短。也确实是下：人物下流。 原著故事叙述的不连贯，每一章都是一个故事，下一章又连着上一章的故事，这种叙事手法容易让人看不下去。 电视剧中的几个主人公1.宝总、2.爷叔、3.汪小姐、4.玲子、5.李李、6.淘淘、7.徐总、8.宏庆，对应一下原著中的这几个人之后完真是一个繁花，一个凋零 电视剧中的阿宝做外贸和炒股，是人人敬仰的宝总。 1.原著中的阿宝并没有详细描述他的职业，只是说做外贸，也没炒股票，他有一个哥哥在香港事业有成，从小被父母过继给了香港人，会时常给阿宝写信，到后来到上海去探亲，但他的父亲并不接受他，书中阿宝穿插在这些人之间，算是个有原则的善良人。 2.电视剧中的爷叔是阿宝的领路人，但是在书中爷叔是一个剃头匠，为人龌龊，追求女邻居不成，就偷窥女邻居偷情并用本子记着时间次数等等，最后交到了女邻居老公手上。在电视剧中的爷叔完全是编剧再创作，只是沿用了爷叔这个名字，横向对比无可比性。 3.电视剧的汪小姐，积极勇敢正直，非常有正能量，爱着宝总。但是原著中的汪小姐则有些毁三观，小说中，宏庆是她的原配老公，电视剧中汪小姐抢了梅瑞和徐总三羊的单子，小说中汪小姐在和阿宝合作，梅瑞用她姘头沪生的关系抢了汪小姐和阿宝的合作。后来汪小姐想要生二胎，就和宏庆假离婚，假嫁给了小毛，后来的假离婚也成了真离婚了，因为汪小姐怀的不确定是他的还是江苏徐总的孩子。起因李李组织了一场去江苏的旅行聚会，邀请了汪小姐，阿宝，沪生，康总和几个太太，徐总负责接待，李李说此次不喝酒，汪小姐执意要喝，最后醉倒，徐总送上楼休息，后就发生了关系。关于谁主动两人各执一词，但是肯定是两人都有这种想法，谁主动也都无所谓了，后来得知汪小姐怀孕徐总怕以后财产纠缠不清，找来谈判多少钱可以打掉，但是汪小姐只想要孩子，即使最后经过多次胎检有很大可能怀的还是畸形儿，连体婴，还是执着要生。 4.玲子，电视剧中她开的夜东京是阿宝投资送给她的，原著中这个店和阿宝没有关系，玲子还可能和葛老师有染，电视剧最后夜东京重装开业，也对应原著，阿宝结尾时进夜东京描述了夜东京装修后的样子。 5.都知道剧中李李是有故事的。原著中李李的故事是这样，她原来在模特班学习，后来被迫参加色情表演，但是她有骨气即使挨打也不肯，和一个有同样遭遇的姐妹一起反抗，最后这个姐妹发动她和几个姐妹一起离开去香港，最后到了香港才发现她们被这个姐妹卖了，进了一个更黑暗的场所，被要求跳裸舞，在人池里跳钢管舞做一些下流的动作，一起被卖的姐妹不得已最后不得不妥协，但是李李宁愿被打还是不肯，最后被打针迷晕被在下腹刺了一朵红色玫瑰和蝴蝶的纹身，这个纹身也成了她的梦魇，也就在最绝望的时候这个夜场的老板周先生发现了她，同时良心发现放了李李给她租了酒店，为了赎罪要联系医院给她祛除身上的纹身，同时找到了卖她的人，把她封在铁通用水泥灌注后，丢下海里。李李自然而然成了周先生的情妇，后来周先生携带家眷移民加拿大，临走的时候安顿李李回到上海，并给她清除了玫瑰纹身。李李到上海后开了至真园，后来遇到阿宝两人互生情愫，发生了一夜情，并把她的遭遇讲给了阿宝，因为悲惨的遭遇也对感情无法自信的表达，阿宝因为儿时的蓓蒂也一直没有开展过认真的感情，两人相互试探，又退缩，最后结局李李选择了出家为尼，寺院梯度要求邀请她的家人，她叫来了阿宝，康总夫妇和沪生为她见证，她选择出家也是因为她从小就在这样的环境里熏陶， 她妈妈信佛，她弟弟要出家被家人反对后跳楼自杀，这也成了她的心病，最后在寺庙才能心中平静。 电视剧中最后汪小姐去还车的时候看到至真园被绿色围挡包围，霓虹灯不在亮，也对应原著李李出家后阿宝回来经过至真园的场景。 6.陶陶在剧中阿宝的铁哥们，被芳妹压的喘不过气，原著中陶陶到处沾花惹草，送大闸蟹的客户，女邻居等等，芳妹无可奈何，最后陶陶和夜东京的小琴搞到了一起，并非要和芳妹离婚，最后也终于离了婚，他签字以后高兴的去找小琴，在他告诉了小琴这个消息后，两人开心庆祝结果他们住的4层的栏杆因为生锈断裂，小琴摔下来死了，（对应电视剧中金美林老公和小江西的那一段）警察带陶陶去调查，最后认定是意外，也在调查中警察调查到小琴的日记，发现小琴对陶陶并非真心，一直在骗他并且伪装成可怜的样子，还有些讨厌他，只是想在上海能居住下来。 7.剧中徐总见人说话有点自己的小心思，最后为完成对宝总的承诺，不惜下跪帮助汪小姐，最后说江湖再见杀青。原著中徐总事业有成，到处猎艳，对李李，对汪小姐都有想法，最后徐总拉着阿宝去医院探望汪小姐了解情况得知胎儿很可能是畸形汪小姐还执着要生，也没有细说他的心情，最后要去医生哪里了解情况就没在介绍…… 8.宏庆剧中是个富二代，追求汪小姐，最后一起成立了明珠公司，原著中他出场和汪小姐就是夫妻关系，是公职人员为生二胎和汪小姐假离婚，最后成了真离婚。 原著中围绕小毛，沪生，阿宝三个人讲的故事，电视剧对原著改动非常大，繁花凋零改编成了繁花似锦。应该当成两个故事看，小说中和电视剧中我们都能已上帝视角俯视他们，但是事情发展是遵循一定逻辑，原著的写作手法是跳跃性的，故事不连贯，不容易读的下去，建议不要看原著了，看看电视剧繁花就挺好。\n",
      "投诉 exceed the max sequence length of 126. The exceeded part will be truncated and ignored. You are recommended to split your long text into several sentences within 126 tokens beforehand.\n",
      "2024-08-24 03:17:49 WARNING Input tokens 看了电视剧繁花之后，读了小说原著。电视剧版本和小说版本讲的完全是两回事，电视剧里每个人都繁花似锦，小说里除了阿宝都繁花凋零。 作者讲他的初衷是宁繁毋略，宁下毋高，书里也确实是这样繁：全是鸡毛蒜皮家长里短。也确实是下：人物下流。 原著故事叙述的不连贯，每一章都是一个故事，下一章又连着上一章的故事，这种叙事手法容易让人看不下去。 电视剧中的几个主人公1.宝总、2.爷叔、3.汪小姐、4.玲子、5.李李、6.淘淘、7.徐总、8.宏庆，对应一下原著中的这几个人之后完真是一个繁花，一个凋零 电视剧中的阿宝做外贸和炒股，是人人敬仰的宝总。 1.原著中的阿宝并没有详细描述他的职业，只是说做外贸，也没炒股票，他有一个哥哥在香港事业有成，从小被父母过继给了香港人，会时常给阿宝写信，到后来到上海去探亲，但他的父亲并不接受他，书中阿宝穿插在这些人之间，算是个有原则的善良人。 2.电视剧中的爷叔是阿宝的领路人，但是在书中爷叔是一个剃头匠，为人龌龊，追求女邻居不成，就偷窥女邻居偷情并用本子记着时间次数等等，最后交到了女邻居老公手上。在电视剧中的爷叔完全是编剧再创作，只是沿用了爷叔这个名字，横向对比无可比性。 3.电视剧的汪小姐，积极勇敢正直，非常有正能量，爱着宝总。但是原著中的汪小姐则有些毁三观，小说中，宏庆是她的原配老公，电视剧中汪小姐抢了梅瑞和徐总三羊的单子，小说中汪小姐在和阿宝合作，梅瑞用她姘头沪生的关系抢了汪小姐和阿宝的合作。后来汪小姐想要生二胎，就和宏庆假离婚，假嫁给了小毛，后来的假离婚也成了真离婚了，因为汪小姐怀的不确定是他的还是江苏徐总的孩子。起因李李组织了一场去江苏的旅行聚会，邀请了汪小姐，阿宝，沪生，康总和几个太太，徐总负责接待，李李说此次不喝酒，汪小姐执意要喝，最后醉倒，徐总送上楼休息，后就发生了关系。关于谁主动两人各执一词，但是肯定是两人都有这种想法，谁主动也都无所谓了，后来得知汪小姐怀孕徐总怕以后财产纠缠不清，找来谈判多少钱可以打掉，但是汪小姐只想要孩子，即使最后经过多次胎检有很大可能怀的还是畸形儿，连体婴，还是执着要生。 4.玲子，电视剧中她开的夜东京是阿宝投资送给她的，原著中这个店和阿宝没有关系，玲子还可能和葛老师有染，电视剧最后夜东京重装开业，也对应原著，阿宝结尾时进夜东京描述了夜东京装修后的样子。 5.都知道剧中李李是有故事的。原著中李李的故事是这样，她原来在模特班学习，后来被迫参加色情表演，但是她有骨气即使挨打也不肯，和一个有同样遭遇的姐妹一起反抗，最后这个姐妹发动她和几个姐妹一起离开去香港，最后到了香港才发现她们被这个姐妹卖了，进了一个更黑暗的场所，被要求跳裸舞，在人池里跳钢管舞做一些下流的动作，一起被卖的姐妹不得已最后不得不妥协，但是李李宁愿被打还是不肯，最后被打针迷晕被在下腹刺了一朵红色玫瑰和蝴蝶的纹身，这个纹身也成了她的梦魇，也就在最绝望的时候这个夜场的老板周先生发现了她，同时良心发现放了李李给她租了酒店，为了赎罪要联系医院给她祛除身上的纹身，同时找到了卖她的人，把她封在铁通用水泥灌注后，丢下海里。李李自然而然成了周先生的情妇，后来周先生携带家眷移民加拿大，临走的时候安顿李李回到上海，并给她清除了玫瑰纹身。李李到上海后开了至真园，后来遇到阿宝两人互生情愫，发生了一夜情，并把她的遭遇讲给了阿宝，因为悲惨的遭遇也对感情无法自信的表达，阿宝因为儿时的蓓蒂也一直没有开展过认真的感情，两人相互试探，又退缩，最后结局李李选择了出家为尼，寺院梯度要求邀请她的家人，她叫来了阿宝，康总夫妇和沪生为她见证，她选择出家也是因为她从小就在这样的环境里熏陶， 她妈妈信佛，她弟弟要出家被家人反对后跳楼自杀，这也成了她的心病，最后在寺庙才能心中平静。 电视剧中最后汪小姐去还车的时候看到至真园被绿色围挡包围，霓虹灯不在亮，也对应原著李李出家后阿宝回来经过至真园的场景。 6.陶陶在剧中阿宝的铁哥们，被芳妹压的喘不过气，原著中陶陶到处沾花惹草，送大闸蟹的客户，女邻居等等，芳妹无可奈何，最后陶陶和夜东京的小琴搞到了一起，并非要和芳妹离婚，最后也终于离了婚，他签字以后高兴的去找小琴，在他告诉了小琴这个消息后，两人开心庆祝结果他们住的4层的栏杆因为生锈断裂，小琴摔下来死了，（对应电视剧中金美林老公和小江西的那一段）警察带陶陶去调查，最后认定是意外，也在调查中警察调查到小琴的日记，发现小琴对陶陶并非真心，一直在骗他并且伪装成可怜的样子，还有些讨厌他，只是想在上海能居住下来。 7.剧中徐总见人说话有点自己的小心思，最后为完成对宝总的承诺，不惜下跪帮助汪小姐，最后说江湖再见杀青。原著中徐总事业有成，到处猎艳，对李李，对汪小姐都有想法，最后徐总拉着阿宝去医院探望汪小姐了解情况得知胎儿很可能是畸形汪小姐还执着要生，也没有细说他的心情，最后要去医生哪里了解情况就没在介绍…… 8.宏庆剧中是个富二代，追求汪小姐，最后一起成立了明珠公司，原著中他出场和汪小姐就是夫妻关系，是公职人员为生二胎和汪小姐假离婚，最后成了真离婚。 原著中围绕小毛，沪生，阿宝三个人讲的故事，电视剧对原著改动非常大，繁花凋零改编成了繁花似锦。应该当成两个故事看，小说中和电视剧中我们都能已上帝视角俯视他们，但是事情发展是遵循一定逻辑，原著的写作手法是跳跃性的，故事不连贯，不容易读的下去，建议不要看原著了，看看电视剧繁花就挺好。\n",
      "投诉 exceed the max sequence length of 126. The exceeded part will be truncated and ignored. You are recommended to split your long text into several sentences within 126 tokens beforehand.\n",
      "2024-08-24 03:17:49 WARNING Input tokens 为什么是非专业评价呢，因为我既非影视剧专业出身，不会使用专业的术语词汇，也不是王家卫电影的研究学者，只想站在观众的角度来谈谈看法。\n",
      "镜头下的《繁花》：一场如梦似幻的沪上嘉年华\n",
      "王家卫是尖沙咀长大的上海人，被香港文化洗礼，却也怀揣着对上海故土的迷恋。\n",
      "他过往的很多电影都在呈现他视角下的上海，最著名的一部是《花样年华》，梁朝伟那袅袅娜娜暧昧的烟圈和张曼玉风情万种的旗袍身姿在上海小巷里散发着无与伦比的旧上海风情。\n",
      "王家卫镜头下的上海，总是一股浓浓的暗黑系迷离风格，充满着对写意性美学的追求，他的拍摄角度很大胆很有特点：\n",
      "1、随处可见的遮蔽与窥视\n",
      "他喜欢用旁观者的视角讲故事，注重构图，很多人物镜头都是1/3格式，或是用帘布、玻璃、隔断、墙角等等构成窥视的效果，有着强烈的叙事意味。\n",
      "2、手提拍摄\n",
      "手提摄像机拍摄，人为地造成画面的模糊感，增加了故事情节的不确定性（动态感配图难找，大家自行看剧体会）。\n",
      "3、夸张的广角镜头与距离感\n",
      "人物有时会被挤压在广角景深的边边角角，强化了画面的压迫感。\n",
      "4、善于用光线与色彩营造氛围\n",
      "我们在《繁花》中看到了各种灯，街灯，台灯，水晶吊灯，霓虹灯……色彩缤纷，上海老洋房的彩色玻璃花窗、海派风情的红砖石库门、复古花砖、墨绿、金酒红色的大面积应用，大多时候美丽奢华，呈现出万花筒般的绮丽风情，这些都为剧情推进营造出了优秀的氛围，有紧张激烈的，有暧昧多情的，有孤寂无奈的，有市井烟火的，千姿百态。\n",
      "5、使用大光圈拍摄人像\n",
      "很多人物出现的镜头是用大光圈呈现的，使得人物显得更加得神秘、浪漫、令人难以捉摸。\n",
      "6、喜欢夜间光线下拍摄\n",
      "全剧90%都是夜间光线下的拍摄，这符合王家卫一贯的风格，夜色下的一切人或事物都会被笼罩在神秘的面纱之下，很容易通过幻梦般的光晕和色彩来凸显人物和剧情。\n",
      "《繁花》配乐：港风歌曲大型怀旧现场\n",
      "《繁花》中，几乎能听到所有的音乐类型，可谓万花齐放，但最突出最让人印象深刻的还是港风歌曲（含粤语和普通话歌曲，均为90年代的流行曲）。\n",
      "全剧此类歌曲共计57首。\n",
      "有烘托生意场上励志图强的《安妮》（王杰）、《爱拼才会赢》、《冬天里的一把火》（费翔），有凸显汪小姐与宝总、宝总与雪芝之间情感拉扯的《执迷不悔》（王菲）、《偷心》（张学友），宝总与雪芝在香港重逢时曾响起《随缘》（温兆伦）。\n",
      "以及交错响起的众多歌曲如《我的未来不是梦》（张雨生）、《光辉岁月》（Beyond）、《不再犹豫》（Beyond）、《喜欢你》（Beyond）、《一生何求》（陈百强）、《你是我胸口永远的痛》（王杰）……\n",
      "当演到玲子在东京与宝总相遇以及玲子初回上海的时候，背景旋律总是那首经典的《东京爱情故事》，听起来十分亲切。\n",
      "王家卫很聪明，与其用新打造的音乐去搭配新的故事，不如用经典的文化符号—音乐来直接勾勒出那个年代的形象，歌声一起，不用多做铺设，信息量直接就出来了。这是90年代大型集体回忆现场，是经历过那个年代人们的共同的梦。\n",
      "他安排老牌港星前来客串，如温兆伦、钟镇涛、赵雅芝（只闻其名）、费翔（高仿版本）等，用意与歌曲如出一辙。\n",
      "除此之外，还有两种配乐风格值得关注。\n",
      "一是戏曲名段的频频出现。\n",
      "这其中最具代表性的就是玲子住的亭子间的楼下那位颇有故事感的史老师，戴着金丝边眼镜温文尔雅的“史老师”，被网友认为是最像上海知识分子的角色，扮演者正是上海京剧院梅派青衣史依弘。\n",
      "剧中史老师唱的《贵妃醉酒》，酒醉时分，思念伊人，这是剧中的史老师和玲子共同的处境；还有收音机播出的《锁麟囊》，讲述的是一个随手相赠，种下善果的故事，喻示着玲子在东京对宝总的帮助，为她自己种下了一个不错的未来。\n",
      "二是西方配乐的出现，通过古典、摇滚、探戈、拉美舞曲等众多风格，打造了本剧一座梦呓般的音乐迷宫。\n",
      "代表性曲目有《My Shawl》、《Jungle Drums》、《La Donna Romantica》、《Da'rk Cha'r'i'o't》等等。\n",
      "王家卫特别擅长用镜头和音乐来表现时间、空间和情感的流逝与缅怀，对城市变迁和人情世态变化观察敏锐，善于探讨人类情感的复杂性和关系的复杂性。\n",
      "《繁花》的叙事和细节：回忆多却不“杀”，稍显凌乱跳脱\n",
      "《繁花》拍的是新中国的上海，聚焦在上世纪90年代初，改革开放伊始，新事物鳞次栉比，老贵族如阿宝，“新钱”如强慕杰开始剑拔弩张，黄河路、进贤路、南京路等发生着一系列关于证券、股票、实业、资本之间的共生博弈的故事，商战场景正是：“不是东风压倒西风，就是西风压倒东风”。\n",
      "《繁花》的生意场被王家卫拍出了民国间谍片的感觉，谈个生意像是大型黑社会碰头现场，仿佛剧情推进的下一秒，杜月笙就要出场，“百乐门”就要响起爵士乐。一条街“黄河路”被拍成了一个江湖，有大侠（宝总），有扫地僧（爷叔），有大智若愚的旁观者（范总），有神秘人物（李李），有愚笨可爱的富二代（魏总）、有传说（金凤凰），而玲子，更像是《新龙门客栈》里的老板娘金镶玉，不那么风情罢了。\n",
      "上海的里子和外表都被王家卫拍得很好看，很摩登，很市井，又充满着人情世故。剧中老上海的弄堂、亭子间、小卖部、霓虹灯、马赛克、水磨石、古典欧式、巴洛克风的建筑都做了很好的还原，很有年代代入感。\n",
      "上海本帮菜如排骨年糕、黄鱼捞面、干炒牛河、泡饭，香港菜如仙鹤神针、川乌、船王炒饭、大王蛇等都被如数家珍地呈现了出来，表现出王家卫对粤港交融文化的熟稔和深厚感情。\n",
      "全剧按照时间线在推进，又穿插着各种回忆情节，老歌，以及阿宝的旁白。可惜的是，本剧有无数的回忆，却不够“杀”，反而让情节稍显凌乱跳脱，上一秒还在讲生意场的你死我活，下一秒就开始了阿宝对于雪芝的回忆；王菲的《执迷不悔》总伴随着汪小姐的内心挣扎响起，却让人难免觉得重复与单调，不能打动人。\n",
      "《繁花》中的人物角色\n",
      "毫无疑问，胡歌成功演绎了宝总，胡歌就是阿宝，他的气质与宝总完美融合，他演绎出的深情和能力让人信服。但剧版的宝总成长之路没有拍出来，他在商场上的杀伐决断、对人情世故的轻松拿捏、刻在骨子里的深深善意从何人来，我们只看到他与雪芝的片刻过往以及与玲子、汪小姐的零碎片段，对这个人物的成长线却仍然不甚了解。宝总这个极具魅力的人物如无根之木，无处寻源。\n",
      "辛芷蕾饰演的李李，复古老钱风的穿搭，皮草外套，夸张配饰，高挑身材，丰颐妙目，黑发红唇，极具港风，张扬霸气，雍容华贵，是行走在暗夜里的一朵迷人的野玫瑰。\n",
      "她让我重新定义了老板娘这个角色，尤其是餐厅老板娘，不光是迎来送往，拿捏人心，关注业绩，还得眼观六路耳听八方，成为一个无可替代的“情报机构”，同时还得对股市、资本市场了如指掌。同时，她也很好地演出了王家卫对人心复杂性的理解：声东击西、欲拒还迎、不露声色、出其不意……都被她演绎得不露痕迹。\n",
      "她是宝总在生意场上最欣赏的一个女性角色，四两拨千斤，干翻了黄河路，也因为太过出色而成为了黄河路的“公敌”。\n",
      "“小阿嫂”，一个我认为演的特别好的小配角，被网友质疑太老与陶陶不搭，但演员很好地演出了小阿嫂市井而不油腻，风情而不风骚的特点，那上楼梯的几步摇，那一口吴侬软语真是酥到了人的骨子里，难怪陶陶为其神魂颠倒。\n",
      "与“小阿嫂”对应的是陶陶的妻子芳妹，这是个被导演处理得很巧妙的角色，她全程没有露过脸。王家卫想告诉我们，她就是个可以被忽视被模糊，随时可以被忘记，不值得被记住的小角色，她是中年油腻女性的代表，是个充满了动物本能而失掉人类细腻情感的人物，是已婚男性的鸡肋和绝望，或者希望（因为可以传宗接代）。\n",
      "小阿嫂再如何，也不会变成芳妹。陶陶守着一段没有爱情的婚姻，眼看着心中的红玫瑰嫁作他人妇……这就是人间真实。\n",
      "王家卫镜头下的人物总有着扑朔迷离的台词，一半靠说，一半靠猜，倒是很符合镜头的神秘迷离之感，但本剧又有不同。\n",
      "《繁花》有着《花样年华》的光影，《东邪西毒》的台词，《一代宗师》的大事件场面，却总让人感觉很多演员的演出或浮夸造作，用力过猛，像是很多幕话剧的拼接；又或者故作高深，实则悬浮，像极了中年版的《小时代》。\n",
      "得失不论，毁誉由人，《繁花》之下，繁华落幕。无论如何，这是王家卫眼中的沪上梦幻年华，是他对一个年代一座城的怀念，我们须细品，再细品，才不枉王导的十年一剑。\n",
      "投诉\n",
      "© 本文版权归作者 剧评官无机之糖 所有，任何形式转载请联系作者。 exceed the max sequence length of 126. The exceeded part will be truncated and ignored. You are recommended to split your long text into several sentences within 126 tokens beforehand.\n",
      "2024-08-24 03:17:49 WARNING Input tokens 看了电视剧繁花之后，读了小说原著。电视剧版本和小说版本讲的完全是两回事，电视剧里每个人都繁花似锦，小说里除了阿宝都繁花凋零。 作者讲他的初衷是宁繁毋略，宁下毋高，书里也确实是这样繁：全是鸡毛蒜皮家长里短。也确实是下：人物下流。 原著故事叙述的不连贯，每一章都是一个故事，下一章又连着上一章的故事，这种叙事手法容易让人看不下去。 电视剧中的几个主人公1.宝总、2.爷叔、3.汪小姐、4.玲子、5.李李、6.淘淘、7.徐总、8.宏庆，对应一下原著中的这几个人之后完真是一个繁花，一个凋零 电视剧中的阿宝做外贸和炒股，是人人敬仰的宝总。 1.原著中的阿宝并没有详细描述他的职业，只是说做外贸，也没炒股票，他有一个哥哥在香港事业有成，从小被父母过继给了香港人，会时常给阿宝写信，到后来到上海去探亲，但他的父亲并不接受他，书中阿宝穿插在这些人之间，算是个有原则的善良人。 2.电视剧中的爷叔是阿宝的领路人，但是在书中爷叔是一个剃头匠，为人龌龊，追求女邻居不成，就偷窥女邻居偷情并用本子记着时间次数等等，最后交到了女邻居老公手上。在电视剧中的爷叔完全是编剧再创作，只是沿用了爷叔这个名字，横向对比无可比性。 3.电视剧的汪小姐，积极勇敢正直，非常有正能量，爱着宝总。但是原著中的汪小姐则有些毁三观，小说中，宏庆是她的原配老公，电视剧中汪小姐抢了梅瑞和徐总三羊的单子，小说中汪小姐在和阿宝合作，梅瑞用她姘头沪生的关系抢了汪小姐和阿宝的合作。后来汪小姐想要生二胎，就和宏庆假离婚，假嫁给了小毛，后来的假离婚也成了真离婚了，因为汪小姐怀的不确定是他的还是江苏徐总的孩子。起因李李组织了一场去江苏的旅行聚会，邀请了汪小姐，阿宝，沪生，康总和几个太太，徐总负责接待，李李说此次不喝酒，汪小姐执意要喝，最后醉倒，徐总送上楼休息，后就发生了关系。关于谁主动两人各执一词，但是肯定是两人都有这种想法，谁主动也都无所谓了，后来得知汪小姐怀孕徐总怕以后财产纠缠不清，找来谈判多少钱可以打掉，但是汪小姐只想要孩子，即使最后经过多次胎检有很大可能怀的还是畸形儿，连体婴，还是执着要生。 4.玲子，电视剧中她开的夜东京是阿宝投资送给她的，原著中这个店和阿宝没有关系，玲子还可能和葛老师有染，电视剧最后夜东京重装开业，也对应原著，阿宝结尾时进夜东京描述了夜东京装修后的样子。 5.都知道剧中李李是有故事的。原著中李李的故事是这样，她原来在模特班学习，后来被迫参加色情表演，但是她有骨气即使挨打也不肯，和一个有同样遭遇的姐妹一起反抗，最后这个姐妹发动她和几个姐妹一起离开去香港，最后到了香港才发现她们被这个姐妹卖了，进了一个更黑暗的场所，被要求跳裸舞，在人池里跳钢管舞做一些下流的动作，一起被卖的姐妹不得已最后不得不妥协，但是李李宁愿被打还是不肯，最后被打针迷晕被在下腹刺了一朵红色玫瑰和蝴蝶的纹身，这个纹身也成了她的梦魇，也就在最绝望的时候这个夜场的老板周先生发现了她，同时良心发现放了李李给她租了酒店，为了赎罪要联系医院给她祛除身上的纹身，同时找到了卖她的人，把她封在铁通用水泥灌注后，丢下海里。李李自然而然成了周先生的情妇，后来周先生携带家眷移民加拿大，临走的时候安顿李李回到上海，并给她清除了玫瑰纹身。李李到上海后开了至真园，后来遇到阿宝两人互生情愫，发生了一夜情，并把她的遭遇讲给了阿宝，因为悲惨的遭遇也对感情无法自信的表达，阿宝因为儿时的蓓蒂也一直没有开展过认真的感情，两人相互试探，又退缩，最后结局李李选择了出家为尼，寺院梯度要求邀请她的家人，她叫来了阿宝，康总夫妇和沪生为她见证，她选择出家也是因为她从小就在这样的环境里熏陶， 她妈妈信佛，她弟弟要出家被家人反对后跳楼自杀，这也成了她的心病，最后在寺庙才能心中平静。 电视剧中最后汪小姐去还车的时候看到至真园被绿色围挡包围，霓虹灯不在亮，也对应原著李李出家后阿宝回来经过至真园的场景。 6.陶陶在剧中阿宝的铁哥们，被芳妹压的喘不过气，原著中陶陶到处沾花惹草，送大闸蟹的客户，女邻居等等，芳妹无可奈何，最后陶陶和夜东京的小琴搞到了一起，并非要和芳妹离婚，最后也终于离了婚，他签字以后高兴的去找小琴，在他告诉了小琴这个消息后，两人开心庆祝结果他们住的4层的栏杆因为生锈断裂，小琴摔下来死了，（对应电视剧中金美林老公和小江西的那一段）警察带陶陶去调查，最后认定是意外，也在调查中警察调查到小琴的日记，发现小琴对陶陶并非真心，一直在骗他并且伪装成可怜的样子，还有些讨厌他，只是想在上海能居住下来。 7.剧中徐总见人说话有点自己的小心思，最后为完成对宝总的承诺，不惜下跪帮助汪小姐，最后说江湖再见杀青。原著中徐总事业有成，到处猎艳，对李李，对汪小姐都有想法，最后徐总拉着阿宝去医院探望汪小姐了解情况得知胎儿很可能是畸形汪小姐还执着要生，也没有细说他的心情，最后要去医生哪里了解情况就没在介绍…… 8.宏庆剧中是个富二代，追求汪小姐，最后一起成立了明珠公司，原著中他出场和汪小姐就是夫妻关系，是公职人员为生二胎和汪小姐假离婚，最后成了真离婚。 原著中围绕小毛，沪生，阿宝三个人讲的故事，电视剧对原著改动非常大，繁花凋零改编成了繁花似锦。应该当成两个故事看，小说中和电视剧中我们都能已上帝视角俯视他们，但是事情发展是遵循一定逻辑，原著的写作手法是跳跃性的，故事不连贯，不容易读的下去，建议不要看原著了，看看电视剧繁花就挺好。\n",
      "投诉 exceed the max sequence length of 126. The exceeded part will be truncated and ignored. You are recommended to split your long text into several sentences within 126 tokens beforehand.\n",
      "2024-08-24 03:17:50 WARNING Input tokens 看了电视剧繁花之后，读了小说原著。电视剧版本和小说版本讲的完全是两回事，电视剧里每个人都繁花似锦，小说里除了阿宝都繁花凋零。 作者讲他的初衷是宁繁毋略，宁下毋高，书里也确实是这样繁：全是鸡毛蒜皮家长里短。也确实是下：人物下流。 原著故事叙述的不连贯，每一章都是一个故事，下一章又连着上一章的故事，这种叙事手法容易让人看不下去。 电视剧中的几个主人公1.宝总、2.爷叔、3.汪小姐、4.玲子、5.李李、6.淘淘、7.徐总、8.宏庆，对应一下原著中的这几个人之后完真是一个繁花，一个凋零 电视剧中的阿宝做外贸和炒股，是人人敬仰的宝总。 1.原著中的阿宝并没有详细描述他的职业，只是说做外贸，也没炒股票，他有一个哥哥在香港事业有成，从小被父母过继给了香港人，会时常给阿宝写信，到后来到上海去探亲，但他的父亲并不接受他，书中阿宝穿插在这些人之间，算是个有原则的善良人。 2.电视剧中的爷叔是阿宝的领路人，但是在书中爷叔是一个剃头匠，为人龌龊，追求女邻居不成，就偷窥女邻居偷情并用本子记着时间次数等等，最后交到了女邻居老公手上。在电视剧中的爷叔完全是编剧再创作，只是沿用了爷叔这个名字，横向对比无可比性。 3.电视剧的汪小姐，积极勇敢正直，非常有正能量，爱着宝总。但是原著中的汪小姐则有些毁三观，小说中，宏庆是她的原配老公，电视剧中汪小姐抢了梅瑞和徐总三羊的单子，小说中汪小姐在和阿宝合作，梅瑞用她姘头沪生的关系抢了汪小姐和阿宝的合作。后来汪小姐想要生二胎，就和宏庆假离婚，假嫁给了小毛，后来的假离婚也成了真离婚了，因为汪小姐怀的不确定是他的还是江苏徐总的孩子。起因李李组织了一场去江苏的旅行聚会，邀请了汪小姐，阿宝，沪生，康总和几个太太，徐总负责接待，李李说此次不喝酒，汪小姐执意要喝，最后醉倒，徐总送上楼休息，后就发生了关系。关于谁主动两人各执一词，但是肯定是两人都有这种想法，谁主动也都无所谓了，后来得知汪小姐怀孕徐总怕以后财产纠缠不清，找来谈判多少钱可以打掉，但是汪小姐只想要孩子，即使最后经过多次胎检有很大可能怀的还是畸形儿，连体婴，还是执着要生。 4.玲子，电视剧中她开的夜东京是阿宝投资送给她的，原著中这个店和阿宝没有关系，玲子还可能和葛老师有染，电视剧最后夜东京重装开业，也对应原著，阿宝结尾时进夜东京描述了夜东京装修后的样子。 5.都知道剧中李李是有故事的。原著中李李的故事是这样，她原来在模特班学习，后来被迫参加色情表演，但是她有骨气即使挨打也不肯，和一个有同样遭遇的姐妹一起反抗，最后这个姐妹发动她和几个姐妹一起离开去香港，最后到了香港才发现她们被这个姐妹卖了，进了一个更黑暗的场所，被要求跳裸舞，在人池里跳钢管舞做一些下流的动作，一起被卖的姐妹不得已最后不得不妥协，但是李李宁愿被打还是不肯，最后被打针迷晕被在下腹刺了一朵红色玫瑰和蝴蝶的纹身，这个纹身也成了她的梦魇，也就在最绝望的时候这个夜场的老板周先生发现了她，同时良心发现放了李李给她租了酒店，为了赎罪要联系医院给她祛除身上的纹身，同时找到了卖她的人，把她封在铁通用水泥灌注后，丢下海里。李李自然而然成了周先生的情妇，后来周先生携带家眷移民加拿大，临走的时候安顿李李回到上海，并给她清除了玫瑰纹身。李李到上海后开了至真园，后来遇到阿宝两人互生情愫，发生了一夜情，并把她的遭遇讲给了阿宝，因为悲惨的遭遇也对感情无法自信的表达，阿宝因为儿时的蓓蒂也一直没有开展过认真的感情，两人相互试探，又退缩，最后结局李李选择了出家为尼，寺院梯度要求邀请她的家人，她叫来了阿宝，康总夫妇和沪生为她见证，她选择出家也是因为她从小就在这样的环境里熏陶， 她妈妈信佛，她弟弟要出家被家人反对后跳楼自杀，这也成了她的心病，最后在寺庙才能心中平静。 电视剧中最后汪小姐去还车的时候看到至真园被绿色围挡包围，霓虹灯不在亮，也对应原著李李出家后阿宝回来经过至真园的场景。 6.陶陶在剧中阿宝的铁哥们，被芳妹压的喘不过气，原著中陶陶到处沾花惹草，送大闸蟹的客户，女邻居等等，芳妹无可奈何，最后陶陶和夜东京的小琴搞到了一起，并非要和芳妹离婚，最后也终于离了婚，他签字以后高兴的去找小琴，在他告诉了小琴这个消息后，两人开心庆祝结果他们住的4层的栏杆因为生锈断裂，小琴摔下来死了，（对应电视剧中金美林老公和小江西的那一段）警察带陶陶去调查，最后认定是意外，也在调查中警察调查到小琴的日记，发现小琴对陶陶并非真心，一直在骗他并且伪装成可怜的样子，还有些讨厌他，只是想在上海能居住下来。 7.剧中徐总见人说话有点自己的小心思，最后为完成对宝总的承诺，不惜下跪帮助汪小姐，最后说江湖再见杀青。原著中徐总事业有成，到处猎艳，对李李，对汪小姐都有想法，最后徐总拉着阿宝去医院探望汪小姐了解情况得知胎儿很可能是畸形汪小姐还执着要生，也没有细说他的心情，最后要去医生哪里了解情况就没在介绍…… 8.宏庆剧中是个富二代，追求汪小姐，最后一起成立了明珠公司，原著中他出场和汪小姐就是夫妻关系，是公职人员为生二胎和汪小姐假离婚，最后成了真离婚。 原著中围绕小毛，沪生，阿宝三个人讲的故事，电视剧对原著改动非常大，繁花凋零改编成了繁花似锦。应该当成两个故事看，小说中和电视剧中我们都能已上帝视角俯视他们，但是事情发展是遵循一定逻辑，原著的写作手法是跳跃性的，故事不连贯，不容易读的下去，建议不要看原著了，看看电视剧繁花就挺好。\n",
      "投诉 exceed the max sequence length of 126. The exceeded part will be truncated and ignored. You are recommended to split your long text into several sentences within 126 tokens beforehand.\n",
      "2024-08-24 03:17:50 WARNING Input tokens 有了小宝宝以后，追个好剧比登天还难。一部繁花从年前看到过年再到春分。腾讯会员是续了又断，断了又续，来来回回拉拉杂杂如同上海的黄梅雨，直到昨天彻底刷完最后四集，顶着乌青的眼圈上班。\n",
      "在看剧的路上，我也断断续续想了很多。\n",
      "首先感谢王家卫导演。他垂直地打破了一个鄙视，电影圈看不起电视剧如同阳春白雪看不起下里巴人。当一个能把电影拍好拍出风格的名导愿意下场拍长达30集的电视剧，用他独特的风格给国内疲态同质的电视剧市场拔高了质量的高线。也能鼓舞更多的创作者、导演、演员突破鄙视圈，忽视体裁限制，只要有驱动，有思想，没有下里巴人，全是高山流水。\n",
      "他还改变了观众对国产剧的审视，什么时候我们衡量一部作品仅仅用单一的数据、出圈、流量作为爆剧的配置。厉害的人他的眼睛永远锁着的不是一朝一夕，他是要拍点什么留给这个时代，是要说点什么为过去的那个年代做注脚，是永恒而不灭的创造。\n",
      "阿宝做生意的时候，恰逢我也在商海小试牛刀。\n",
      "我遇到的难题，几乎都在剧里找到了缩影。我头疼我的护城河，在我没有核心技术能力保护下被他人拱去。阿宝在做完三羊牌后也被挤出第一承销商的位置。天下熙熙，皆为利来；天下攘攘，皆为利往。在商海里，外面是黄河路的花团锦簇，笑意盈盈。实际上，筷匙之间都是冰冷的数字对抗，谁出价更高，谁能压到更低廉的成本，谁能更沉住气，拿到更多的议价空间。\n",
      "当我看到阿宝只是把三羊的第一笔大单做好，然后笑笑交代范总以后多帮帮汪小姐，再走出黄河路，去闯新的资本市场时。我焦虑的内心也有了平静，做好自己的单，不响不吵，体体面面地结束。我出门去寻找新的机会，你若要再寻我，还是照样给你做得漂漂亮亮的。\n",
      "看阿宝和李李做生意，向来是快、狠、准。在漫长的时间里等待，寻摸一个机会，机会来临的电话响起时也不急不徐，电光火石间做好决定，一剑封喉。这其中不知做了多少沙盘演练，盘剥了多少次的人心。\n",
      "投诉\n",
      "© 本文版权归作者 之南 所有，任何形式转载请联系作者。 exceed the max sequence length of 126. The exceeded part will be truncated and ignored. You are recommended to split your long text into several sentences within 126 tokens beforehand.\n",
      "2024-08-24 03:17:50 WARNING Input tokens 《繁花》这部电视剧，以其细腻的情感描绘和深刻的人物塑造，在中国电视剧领域独树一帜。剧情主要围绕着主人公阿宝的人生历程展开，展现了他与李李、玲子、汪小姐等女性角色之间复杂微妙的情感纠葛，以及他在商业战场上的起伏跌宕。 剧中的阿宝，是一个深具商业头脑和情感纠葛的人物。他与李李的关系从最初的互有矛盾，逐渐发展成为生意上的搭档，再到产生深厚的感情。在商业上，阿宝涉足服装、机械、金融等多个领域，生意越做越大，几乎每次投资都能轰动上海滩。然而，在阿宝的背后，有着玲子和汪小姐这样一直给予他帮助和支持的女性。她们对阿宝都投注了深厚的感情，使阿宝在情感和事业上面临重大的抉择。\n",
      "投诉 exceed the max sequence length of 126. The exceeded part will be truncated and ignored. You are recommended to split your long text into several sentences within 126 tokens beforehand.\n",
      "2024-08-24 03:17:50 WARNING Input tokens 近十多年来追的第一部国产剧。一个原因是冲着王家卫，一个冲着故事背景在上海，一个冲着我的专业领域。通篇看下来，是个不错的标杆商业电视剧。金句基本集中在爷叔。亮点和弱点同样明显。\n",
      "灯光运镜bgm逼格拉满，但30集的很容易让人视觉疲劳。莫名的高级感，如同我准备吃一顿正餐结果上来的全是精致的点心。\n",
      "多故事线运行，搭配巧妙，金美林，景秀，金花，范总配角凸出。但唐嫣和马伊琍喋喋不休的台词，生硬的虚无错过，主角滥情与轻浮，碎片化镜头甚至用力过猛。\n",
      "20集后，投机倒把的神话主角安全下车，弱智化的深圳资本，爽文式的花架子。扣分。\n",
      "投诉\n",
      "© 本文版权归作者 敏哥哥 所有，任何形式转载请联系作者。 exceed the max sequence length of 126. The exceeded part will be truncated and ignored. You are recommended to split your long text into several sentences within 126 tokens beforehand.\n",
      "2024-08-24 03:17:50 WARNING Input tokens 繁花剧评 繁花，一部引人入胜的剧集，以其独特的魅力吸引了众多观众的眼球。在这部作品中，我们可以看到导演对剧情、角色、视觉效果、音乐与配乐等方面的精心安排，呈现出了一部高水平的作品。 一、剧情概述 繁花的故事发生在一个繁华的城市，讲述了主人公在追求梦想的道路上所经历的种种挑战和成长。剧情紧凑，情节跌宕起伏，让观众在欣赏剧情的同时，也能感受到生活的真实与残酷。 二、角色分析 剧中的角色形象鲜明，各具特色。主人公勇敢坚定，面对困难毫不退缩；而其他角色也都有各自的故事和性格，让观众在追剧的过程中，能够与人物产生共鸣。演员们通过对角色的深入剖析，成功地塑造了一个个立体的人物形象。 三、导演风格 导演在繁花中展现了自己独特的艺术风格。他运用丰富的镜头语言和剪辑手法，将故事呈现得既富有张力又细腻动人。此外，导演还巧妙地运用了各种视觉元素，如色彩、构图等，为观众营造出一个充满美感的视觉盛宴。 四、演员表现 演员们在繁花中的表现堪称出色。他们通过精湛的演技，将角色的内心世界和情感变化展现得淋漓尽致。尤其是在一些关键场景中，演员们的表演更是让人热泪盈眶，令观众为之动容。 五、视觉效果 繁花的视觉效果堪称一流。剧组在场景布置、服装道具等方面下足了功夫，为观众呈现出一个充满质感的视觉世界。同时，摄影师通过精心构图和光线运用，将每一个画面都拍摄得美不胜收，让观众在欣赏剧情的同时，也能享受到视觉的愉悦。 六、音乐与配乐 繁花在音乐与配乐方面同样表现出色。剧中的主题曲和插曲旋律优美、动听，既能够凸显剧情主题，又能够激发观众的共鸣。此外，配乐师还巧妙地运用了各种音效和背景音乐，为剧情增色不少，使得整部剧集更加生动有趣。 七、主题深度 繁花的主题深刻而引人思考。剧中通过主人公的成长经历，探讨了梦想、家庭、友情等多个层面的主题。这些主题在现实生活中同样具有普遍性，让观众在欣赏剧情的同时，也能够思考人生的意义和价值。 八、观众反响 繁花自播出以来，便受到了广大观众的热烈追捧和好评。观众们纷纷表示，这部剧集的剧情紧凑、演员表现出色、视觉效果一流，是一部难得佳作。同时，观众们也纷纷在社交媒体上分享自己的观剧心得和感受，形成了一股热潮。 综上所述，繁花作为一部高品质的剧集，在各个方面都表现得相当出色。它成功地吸引了观众的眼球，让人们在欣赏剧情的同时，也能够感受到生活的真实与美好。相信这部剧集将会成为一部经典之作，长久地留在人们的心中。\n",
      "投诉 exceed the max sequence length of 126. The exceeded part will be truncated and ignored. You are recommended to split your long text into several sentences within 126 tokens beforehand.\n",
      "2024-08-24 03:17:51 WARNING Input tokens 追查开车撞宝总的凶手的时候，爷叔和蔡司令有过一段对话：\n",
      "蔡司令：“那宝总手里捏着几百万深圳人割肉割得血淋淋的筹码。”\n",
      "爷叔：“可以讲是血海深仇。但是资本市场报仇，不会开出租车去撞你的，只会叫他什么地方来什么地方去。”\n",
      "深圳帮和宝总在资本市场上的血海深仇，强总后来对玲子讲述，“我们倒下来的时候，四面八方的人都来捡我们掉到地板价的股票，其中也包括阿宝。他带着五十万，从我们这分走了一个小指头。半年后，这个小指头变成几百万，从此在黄河路，一路风光。”\n",
      "深圳帮和宝总在资本市场上有血海深仇，但资本市场报仇，只会在资本市场上去做。宝总在414股票后已经离开资本市场，所以要报仇，首先就得把他引回资本市场。\n",
      "在上一个篇的《从不吃鱼到吃鱼，宝总经历了什么？》里，可以看到李李一直想引宝总回资本市场。本贴主要分析，这是出于南国投强总的指使，还是出于李李个人的目的？\n",
      "南国投的先头部队，从至真园开业第一天起，就经常来顶头包间。\n",
      "第10集，黄河路保卫战后，宝总第一次来顶头包间前，李李和潘经理有一段对话提到南国投——\n",
      "李李：“顶头包间订好了吗？”\n",
      "潘经理：“就等宝总来了。南国投的张总一直在打听，今晚顶头包间是不是宝总订的。还有老板娘跟宝总有什么合作。”\n",
      "李李：“他知道着急就对了。至真园如果只靠它南国投做生意，就没必要开那么多包间。”\n",
      "第11集，南国投大部队即将到达上海，李李给宝总送鲇鱼。在等待宝总来至真园的时候，李李和潘经理也有一段对话提到南国投——\n",
      "潘经理：“老板娘，快8点了，宝总那边还没有消息。”\n",
      "李李：“等，他一定会来的。”\n",
      "潘经理：“南国投的张总在下面一直打听，问老板娘跟宝总有什么合作。”\n",
      "李李：“他管得还真宽。”\n",
      "从这两个对话可以看出，南国投先头部队的张总，并不知道李李要引宝总回资本市场的事情。\n",
      "宝总把鲇鱼送回至真园，李李说，“有些话不方便在黄河路上说。” 李李第一次带宝总去新兰居吃火锅，就是为了避开在至真园的南国投人员。\n",
      "这里可以推断出，李李给宝总送鲇鱼是个人行为，南国投先头部队并没有要引宝总回资本市场（他们确实也没有任何动作）。\n",
      "南国投深圳大部队到达上海，但接下来几个月，南国投上海营业部业绩不佳。\n",
      "在这段时间里，宝总对服饰公司上市的机会动了心。服饰公司上市需要资金推动，宝总找到了宁波老板的资金盘子，但是离掌握主动还是差口气，所以想再做波行情。\n",
      "宝总预计，强总应该差不多要到上海了，必然会有所动作（“南国投这么大门面，中看不中用，要被人家笑话的”）。所以打算守株待兔，让邮票李盯住至真园，到时候跟着强总这条鲇鱼做的行情赚一波。\n",
      "强总终于到上海了。蔡司令跟宝总说，已经在南国投上海营业部安排了倒钩（眼线）。过了一阵子，盯至真园的邮票李有了收获。南国投请来的香港律师，频繁进出至真园，好像在做推介会。宝总嘱咐蔡司令，“让你的倒钩，盯牢营业部资金的进出，等深圳帮的大资金进来，马上通知我们。”\n",
      "但强总很快发现了蔡司令安插在南国投的倒钩，解雇了。这也让强总察觉到，宝总想跟着南国投做的行情赚一波。\n",
      "强总不想让宝总跟着自己做的行情赚钱，安排南国投律师住到了和平饭店，故意留下文件碎片，让宝总拿去分析，想用错误信息迷惑宝总。\n",
      "宝总分析出这是个圈套。为了弄清楚强总为什么要下这个套，宝总第一次找李李打探消息。得知宝总终于来“吃鱼”了，李李明显很得意。\n",
      "从李李那里，宝总得知强总是要“买公司”。最好买的公司是三无板块的公司，而当时的三无板块只有四只股票。通过强总故意留的错误信息，宝总排除了其中两家公司，剩下601和603两家。\n",
      "这次会面后，宝总让蔡司令查证李李的消息，证实上海四个三无板块都在蠢蠢欲动，其中两家（601和603）有大买家进场在做盘，但是吃不准哪一家是佯攻，哪一家是主攻。\n",
      "强总发现宝总没有上当买601和603以外的两家公司的股票，让人去查宝总最近见过谁，查到了李李，于是到至真园兴师问罪。\n",
      "强总：“你知道为什么至真园开业到现在，我们一直很支持你吗？”\n",
      "（南国投来至真园消费，强总视为对李李的支持，因为李李需要赚钱。）\n",
      "李李：“我知道。”\n",
      "强总：“所有饭店说穿了，都是一个场子。我们来，是因为我认为这是我的主场。”\n",
      "（强总认为至真园就是一个场子，也仅仅是一个场子。来至真园是觉得是自己的主场，不需要担心泄露消息。）\n",
      "强总：我看着你从南到北走到这里，你过去那点经历，别人不知道，我还是知道的。你跟谁交朋友，甚至男朋友，我都没有权利干涉。但我希望你清楚关系，因为感情而背叛交情，走到哪里，都是不被原谅的。\n",
      "（强总怀疑李李和宝总的关系是“交男朋友”，这也是黄河路上的传言。强总希望李李不要“因为感情而背叛交情”，不然是“不被原谅的”，还拿李李的过去威胁她。）\n",
      "李李：强总，你太小看我了。\n",
      "(“你太小看我了”，因为李李透露消息给宝总是出自于更深的布局。)\n",
      "李李泄露消息给宝总，显然不是强总的意思。强总不想让宝总跟着南国投做的行情赚钱，所以用错误信息迷惑他。而李李的目的一来是赚钱，二来是让宝总正式回到资本市场，获取信任，也为后续宝总继续做服饰公司上市这条“大鱼”做铺垫（李李早已察觉宝总对服饰公司上市的机会动心）。\n",
      "宝瀛大战过后，服饰公司上市需要券商，宝总请李李帮忙牵线南国投。在至真园顶头包间，宝总和强总正式会面。在这次会面，强总表达了自己对宝总的态度：\n",
      "“你不具备和我合作的资格。你和你的散户朋友是炒股票的，我们是发股票的，你我不在一个层面。你们之前，有一两次侥幸，以后不会一直有。南京路上，没有你的位置。如果你们挡在我的前面，只有被碾成灰一个结果。”\n",
      "强总说宝总的舰队是“你和你的散户朋友”，希望宝总有自知之明，自动出局，如果非要挡在机构前面，那么就是自寻死路。话是难听了点，但确实是强总的心里话。从强总的角度看，这其实是对宝总的忠告。强总要的是宝总认输出局，而不是想引他继续留在资本市场。\n",
      "这次会面后，强总和玲子说起阿宝，“我要告诉你，他没机会赢的。散户的时代已经过去了，未来是机构间的博弈了。风高浪急，容不下他这种个人英雄主义的。”\n",
      "但李李想看到的是宝总继续留在资本市场，在服饰公司上市中和强总一争。强总派人盯李李和宝总在新兰居吃火锅。后来强总向玲子讲李李和宝总的时候，强总总结说，“男的有个梦，就是要成为南京路上的巴菲特。……这个女人用这个梦来忽悠他。”\n",
      "既然宝总不肯听劝自动出局，那么以强总的性格，就会用最极端的手段来对付他。\n",
      "回过头看第11集，爷叔对深圳帮和李李的判断其实相当到位：\n",
      "“深圳帮的目的是上海市场，不是你宝总。你专心做外贸，他们翻天覆地，全都跟你没关系。你要是心不定，她是要来招你魂的。”\n",
      "投诉\n",
      "© 本文版权归作者 Ｖera 所有，任何形式转载请联系作者。 exceed the max sequence length of 126. The exceeded part will be truncated and ignored. You are recommended to split your long text into several sentences within 126 tokens beforehand.\n",
      "2024-08-24 03:17:51 WARNING Input tokens 《繁花》电视剧大爆，可以探讨的角度有很多，这篇我想写写剧中女人的感情与事业。\n",
      "本篇仅针对剧版《繁花》，未读原著，请原著党绕行。\n",
      "开局上来，我觉得汪小姐跟玲子都好聒噪，加上金美林、菱红等等那些女配角，每一集都是砰砰砰锵锵锵地由头吵到尾，当然她们不是真的在吵，但她们说上海话的方式就像是在吵架，仿佛生来就不懂怎么好好地说话一样。我不懂上海话，但知道上海话的腔调由女人的嘴里说出来多半是凌厉的，只是不知道会这么厉害[捂脸] 。同样是上海女人，我更喜欢金科长、潘经理那样绵软轻柔，慢条斯理，却字字分量、不卑不亢的说话方式。\n",
      "跟宝总关系最密切的女人有三个：汪小姐、玲子、李李。\n",
      "初印象是汪小姐太天真太浮躁，她的工作能力能得到上下的认可这一点很不能让人信服；玲子精明市侩，处处像在占宝总的便宜，说话三分真七分假戏谑中又带着几分真情，有时令人难以分辨；李李来路不明，高深莫测，杀伐果断，开一家“至真园”酒楼就把整条黄河路搅了个底朝天，是朵谜一样的野玫瑰。\n",
      "总之，她们都不是国产剧中常见的五官正三观更正的圣母白莲花形象。\n",
      "再来说她们共同的爱慕对象，宝总。他让我想起之前胡歌在《琅琊榜》中扮演的角色梅长苏，确实有几分神似，都是神隐神现，传说中的世外高人，只是宝总更多了几分倜傥，且倜傥中不失风流，风流中不失儒雅。\n",
      "只是，梅长苏对霓凰郡主始终专情，而宝总么，他也不知道自己爱谁，或者说，他从没爱上过谁。好兄弟陶陶曾对宝总直言不讳：“女人对你有情，你对女人有义。”\n",
      "说的很准确，他无论对哪个身边的女人都很好，心疼她们，帮助她们，甚至不惜自己吃亏。但仔细想想，他似乎对身边的任何人都很好，无论是视如父亲的爷叔，还是为他行走在股市刀山火海的“舰队”成员，更别说发小陶陶，甚至小卖部的小老板都很领他的情，黄河路的“老板娘”们也给足他面子。\n",
      "但是，他就是不够爱她们。他分不清自己的感情是否早已随着童年玩伴贝蒂的离去而消失，还是因在雪芝身上看到的人性的功利而失望，或者只是在感动于玲子因为一张机票一张名片就毅然决然回沪为他开起了夜东京，还是惊喜于汪小姐急吼吼地开一夜车解救被“绑架”的他，还有李李那张看不出波澜的漂亮面孔之下无法掩饰的对他的欣赏之情……\n",
      "他与她们都有过暧昧的时刻，除了李李英雄不问来处之外，他与汪小姐和玲子甚至都有很多深刻难忘的回忆，可惜的是，剧中出现了那么多的回忆片段，还配上那么经典的老港风歌曲，回忆却只是回忆，一点也不“杀”。因为宝总并未真的动情，而回忆也出现得实在是太多了有点泛滥。\n",
      "宝总是“渣男”吗，很显然不能用现代社会的这个词汇来形容他，但他是好男人吗，显然也不是。\n",
      "好男人不会给所有女人造成无谓的假象，让所有人都觉得自己有希望；好男人不会在女人表白时选择畏缩，至少该给人家一个明确的交待；好男人不会如此温吞，温吞得似乎在所有人前都是人畜无害，有情有义，无差别对待。\n",
      "这样的男人放在任何时代，都是女人们的克星，他分明很好，好得让你觉得配不上他，但他就是对你不够爱，对你没有承诺。\n",
      "三个女人跟宝总的关系。汪小姐或许让宝总看到了年少时的纯真、勇敢、孩子气，他愿意不计一切保护她，为了她跟爷叔和玲子翻脸，但他只是想保护她，比哥哥保护妹妹多了一点情愫，又比恋人少了点味道。玲子是他的家人，虽然会占他小便宜会任性发脾气，但大是大非面前从不拖后腿，他知道玲子是真心为他，玲子在他心里像个姐姐一样的角色，每天教训弟弟，但弟弟绝不会跟姐姐计较。李李与宝总才华相当，惺惺相惜，他们是完美的合作伙伴，偶尔迸发出的夜灯下，汽车里的浪漫，却也止步于此，两人都背负得太多，深知没有可能，既然没可能，那就这样吧。\n",
      "宝总就这样，用自己的善良和温吞为自己制造了一个竞争对手（汪小姐），一个成熟有魄力的老板娘（玲子），以及一个手段了得分分钟崛起黄河路的角色（李李，其实也是竞争对手）。\n",
      "而三个女人在了解到与宝总无缘之后，汪小姐放下心结，事业上继续成长，与魏总合作搭档，很可能明珠公司就此壮大，汪小姐也成了外贸行业的女强人。玲子与夜东京一起凤凰涅槃，浴火重生，证明了与宝总彻底切割之后不管去到哪里，她依然可以过得很不错。李李袒露了过往，承担了她的过错，在对A先生的回忆中逐渐疗伤，并遁入空门还自己了自由。\n",
      "最勇敢的其实是玲子，因为她从开始就知道这段感情是没有结果的，但她依然选择了追随宝总，而事业上最可能成功的也是玲子，因为她有头脑有章法，会笼络人心，不太感情用事，而李李是有点光环在身上的，做生意方面飘着点仙气，汪小姐很可能会遇到别有用心的老道生意人，栽跟头。\n",
      "开始觉得马伊琍饰演的玲子有些过于精明，令人讨厌，但慢慢地发现她是三个女性角色中最真实最接地气的一个，精明干练，精通人情世故，但有时也不那么世故，重情重义，能接的了小盘子也能担得起大场面。\n",
      "无法评价她们遇到宝总究竟是她们的幸与不幸，但脱离了男人感情束缚、不再内耗的她们，专心搞事业的她们，有了选择自由的她们，是有魅力的，是令人敬服的。这个时候，女性成为了自由的与男性平等的个体，不再依附男人，充满了生命力，只为自己而活。\n",
      "还有三位女服务员的角色，作为配角，她们表现很亮眼，或沉稳或心机或追随，她们敢于直面自己的欲望，敢于犯错也敢于认错，更加敢于重新来过，她们与女主角们站在一起打拼事业，为自己挣得了自由的天地和灵魂。\n",
      "引用最近看到的一本书里的一句话：“女人不是天生的，女人是后天形成的，而最不幸的就是，很多女人终其一生都没明白这个道理。”\n",
      "投诉\n",
      "© 本文版权归作者 剧评官无机之糖 所有，任何形式转载请联系作者。 exceed the max sequence length of 126. The exceeded part will be truncated and ignored. You are recommended to split your long text into several sentences within 126 tokens beforehand.\n",
      "2024-08-24 03:17:51 WARNING Input tokens 午间听了个讲座-翻译文学的现代性，谈及“译作是原作(original text)来世的生命。”倒觉得颇适用于电视剧《繁花》给我的印象，似可转述为-影视创作是原作来世的生命。老实说年初高收视率的霸屏剧《繁花》我并未看全，每每因听觉视觉疲劳弃剧复又经不住铺天盖地的宣发诱惑重新点开续看。且不说上海人的耳朵都受不了的喳巴沪语台词，主角们用力过猛的表演，不符合年代的服饰，夸张的转场，不连贯的剧情，单说略去了小毛/沪生两个角色，便是不完整的繁花啊，工人阶级/干部后代怎么没有提及，就留着资本市场翻云覆雨的富三代宝总，却加了爷叔，调子有点像踩对时代节奏的投资励志片，还有些盖茨比爵士时代的腐味。风头最劲的高调女主汪小姐在原著中只是个讨人厌的反派人物，笔墨甚少。博共情，汇入煽情的流行歌曲BGM，以炒股开场，炒地结尾，这一面目全非的改写重生大杂烩结果是迎合了大众，炒旺了黄河路，回锅了老歌，多个时尚品牌以繁花为SS发布主题，余味绵长。60/70/80/90都能找到共鸣点（不会沪语的Z世代共鸣点可能要去国语版找？！），确是一次成功的商业化创作。\n",
      "投诉 exceed the max sequence length of 126. The exceeded part will be truncated and ignored. You are recommended to split your long text into several sentences within 126 tokens beforehand.\n",
      "2024-08-24 03:17:51 WARNING Input tokens 王家卫导演拍的电视剧都是品质很好的电影质感，非常高级的视觉效果，很少有这种电视剧出现！故事内容讲述也和其他的电视剧不一样的角度，演员阵容很棒，胡歌表现出色，帅气十足，很好的演绎。其他的演员表演也都在线，服化道很棒！摄影指导鲍德熹的掌镜为该剧带来了电影般的质感和强烈的视觉感染力。真希望我们有更多优秀的电视剧作品出现！\n",
      "投诉 exceed the max sequence length of 126. The exceeded part will be truncated and ignored. You are recommended to split your long text into several sentences within 126 tokens beforehand.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m comment \u001b[38;5;129;01min\u001b[39;00m comments:\n\u001b[1;32m      8\u001b[0m     words \u001b[38;5;241m=\u001b[39m jieba\u001b[38;5;241m.\u001b[39mlcut(comment)  \u001b[38;5;66;03m# 使用 Jieba 进行分词\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m     entities \u001b[38;5;241m=\u001b[39m \u001b[43mrecognizer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcomment\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# 使用 HanLP 进行命名实体识别\u001b[39;00m\n\u001b[1;32m     10\u001b[0m     entity_words \u001b[38;5;241m=\u001b[39m [entity[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m entity \u001b[38;5;129;01min\u001b[39;00m entities \u001b[38;5;28;01mif\u001b[39;00m entity[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNR\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNT\u001b[39m\u001b[38;5;124m'\u001b[39m)]  \u001b[38;5;66;03m# 过滤掉人名和组织名\u001b[39;00m\n\u001b[1;32m     11\u001b[0m     filtered_words\u001b[38;5;241m.\u001b[39mextend([word \u001b[38;5;28;01mfor\u001b[39;00m word \u001b[38;5;129;01min\u001b[39;00m words \u001b[38;5;28;01mif\u001b[39;00m word \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m entity_words])\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/hanlp/common/component.py:36\u001b[0m, in \u001b[0;36mComponent.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     26\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;124;03m    A shortcut for :func:`~hanlp.common.component.predict`.\u001b[39;00m\n\u001b[1;32m     28\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     34\u001b[0m \n\u001b[1;32m     35\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 36\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/hanlp/common/keras_component.py:451\u001b[0m, in \u001b[0;36mKerasComponent.predict\u001b[0;34m(self, data, batch_size, **kwargs)\u001b[0m\n\u001b[1;32m    449\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    450\u001b[0m     inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m  \u001b[38;5;66;03m# if data is a generator, it's usually one-time, not able to transform into a list\u001b[39;00m\n\u001b[0;32m--> 451\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m output \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredict_batch(batch, inputs\u001b[38;5;241m=\u001b[39minputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    452\u001b[0m     results\u001b[38;5;241m.\u001b[39mappend(output)\n\u001b[1;32m    453\u001b[0m num_samples \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m samples_in_batch\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/hanlp/common/keras_component.py:462\u001b[0m, in \u001b[0;36mKerasComponent.predict_batch\u001b[0;34m(self, batch, inputs, **kwargs)\u001b[0m\n\u001b[1;32m    460\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict_batch\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch, inputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    461\u001b[0m     X \u001b[38;5;241m=\u001b[39m batch[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m--> 462\u001b[0m     Y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_on_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    463\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m output \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform\u001b[38;5;241m.\u001b[39mY_to_outputs(Y, X\u001b[38;5;241m=\u001b[39mX, inputs\u001b[38;5;241m=\u001b[39minputs, batch\u001b[38;5;241m=\u001b[39mbatch, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    464\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m output\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/keras/src/engine/training.py:2777\u001b[0m, in \u001b[0;36mModel.predict_on_batch\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m   2773\u001b[0m     iterator \u001b[38;5;241m=\u001b[39m data_adapter\u001b[38;5;241m.\u001b[39msingle_batch_iterator(\n\u001b[1;32m   2774\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdistribute_strategy, x\n\u001b[1;32m   2775\u001b[0m     )\n\u001b[1;32m   2776\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredict_function \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmake_predict_function()\n\u001b[0;32m-> 2777\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2778\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m tf_utils\u001b[38;5;241m.\u001b[39msync_to_numpy_or_python_type(outputs)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:825\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    822\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    824\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 825\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    827\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    828\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:864\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    861\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    862\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[1;32m    863\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[0;32m--> 864\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_variable_creation_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    865\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ALLOW_DYNAMIC_VARIABLE_CREATION:\n\u001b[1;32m    866\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    867\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:148\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    145\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m    146\u001b[0m   (concrete_function,\n\u001b[1;32m    147\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m--> 148\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    149\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:1349\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs)\u001b[0m\n\u001b[1;32m   1345\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1346\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1347\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1348\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1349\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   1350\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1351\u001b[0m     args,\n\u001b[1;32m   1352\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1353\u001b[0m     executing_eagerly)\n\u001b[1;32m   1354\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:196\u001b[0m, in \u001b[0;36mAtomicFunction.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[1;32m    195\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 196\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    197\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    198\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    199\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    200\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    201\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    202\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mlist\u001b[39m(args))\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/tensorflow/python/eager/context.py:1457\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1455\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[1;32m   1456\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1457\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1458\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1459\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1460\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1461\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1462\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1463\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1464\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1465\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1466\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1467\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1471\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[1;32m   1472\u001b[0m   )\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 获取评论内容列，并将其转换为字符串类型\n",
    "comments = df['内容'].astype(str)\n",
    "\n",
    "# 使用 contextlib.redirect_stdout 完全屏蔽输出\n",
    "with contextlib.redirect_stdout(io.StringIO()):\n",
    "    filtered_words = []\n",
    "    for comment in comments:\n",
    "        words = jieba.lcut(comment)  # 使用 Jieba 进行分词\n",
    "        entities = recognizer(comment)  # 使用 HanLP 进行命名实体识别\n",
    "        entity_words = [entity[0] for entity in entities if entity[1] in ('NR', 'NT')]  # 过滤掉人名和组织名\n",
    "        filtered_words.extend([word for word in words if word not in entity_words])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec2a3e7e-1f14-4611-b917-aa6e5f4c6ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取扩展停用词库文件\n",
    "with open('cn_stopwords.txt', 'r', encoding='utf-8') as f:\n",
    "    file_stop_words = set(f.read().splitlines())\n",
    "\n",
    "# 定义并扩展停用词库\n",
    "custom_stop_words = set([\n",
    "    '的', '了', '和', '是', '我', '也', '在', '有', '就', '不', '人', '都', '这个', '上', '很', '你', '他', '她',\n",
    "    '它', '我们', '他们', '她们', '自己', '所以', '因为', '这样', '这里', '那里', '什么', '但是', '如果', '那么',\n",
    "    '还是', '虽然', '不过', '而且', '并且', '关于', '其中', '甚至', '一些', '还有', '或者', '所以', '其实', '另外', '其实',\n",
    "    '以及', '就是', '与', '就', '最', '已经', '非常', '那么', '而', '并', '还', '其中', '所有', '所有的', '还有', '只是',\n",
    "    '几乎', '其他', '而且', '但', '呢', '却', '哇', '哈', '吧', '啊', '的', '嘞', '啦', '吗', '呀'\n",
    "])\n",
    "\n",
    "# 将自定义停用词和文件中的停用词合并\n",
    "stop_words = custom_stop_words.union(file_stop_words)\n",
    "\n",
    "# 过滤停用词和长度小于2的词语\n",
    "filtered_words = [word for word in filtered_words if word not in stop_words and len(word) > 1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95b6f1e6-72e1-4c36-bfca-2ac0f6583cd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 统计词频\n",
    "word_freq = Counter(filtered_words)\n",
    "common_words = word_freq.most_common(30)\n",
    "print(common_words)\n",
    "\n",
    "# 生成词云\n",
    "wordcloud = WordCloud(width=800, height=400, background_color='white').generate_from_frequencies(dict(common_words))\n",
    "\n",
    "# 显示词云图\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis('off')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
