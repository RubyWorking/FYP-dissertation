{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "446c0842-45ae-44ca-ba34-b841821af9cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: jieba in /opt/conda/lib/python3.11/site-packages (0.42.1)\n",
      "Requirement already satisfied: scikit-learn in /opt/conda/lib/python3.11/site-packages (1.3.0)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /opt/conda/lib/python3.11/site-packages (from scikit-learn) (1.24.3)\n",
      "Requirement already satisfied: scipy>=1.5.0 in /opt/conda/lib/python3.11/site-packages (from scikit-learn) (1.11.2)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.11/site-packages (from scikit-learn) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.11/site-packages (from scikit-learn) (3.2.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install jieba scikit-learn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "fa96574f-930c-44bb-84d8-8e41ea3f010d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          用户名    IP                                                 评论  \\\n",
      "0    Vectivus    辽宁        [思考]有人说鲜得来是老师傅退休配方带走了之后就不好吃了。有上海人肉身感受过么[思考]   \n",
      "1  星瞳 /•᷅•᷄\\୭  IP未知  繁华真的美化太多以前的食物了，小时候就没觉得排骨年糕好吃[呆无辜][呆无辜]阿拉老娘做的面拖...   \n",
      "2       阐述你的梦    上海                                    终于看到有人说这家了 是真好吃   \n",
      "3          🌊🌊    上海                                        刚吃的没切【发表图片】   \n",
      "4      小当当童书馆    上海                                         阿平面馆（我记住了）   \n",
      "\n",
      "                   时间  回复数   点赞数  label  \n",
      "0 2024-01-14 12:54:51  114  8358      1  \n",
      "1 2024-01-14 15:20:34   40  4544      1  \n",
      "2 2024-01-14 14:16:27   20   282      1  \n",
      "3 2024-01-14 14:00:47   32   747      1  \n",
      "4 2024-01-15 13:42:36    3   124      0  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import jieba\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# 假设我们要处理的数据文件已经上传并读取\n",
    "file_path = 'Blossoms_Food_Tiktok4.xlsx'\n",
    "data = pd.read_excel(file_path)\n",
    "\n",
    "# 扩展后的关键词列表\n",
    "keywords = [\n",
    "    \"打卡了\", \"刚去\", \"吃了\", \"去过\", \"吃过\", \"好吃\", \"去吃\", \"想吃\", \"超想吃\", \"度假\", \"出游\",\n",
    "    \"旅游\", \"打卡\", \"景点\", \"想去\", \"去玩\", \"参观\", \"游玩\", \"去看看\", \"旅行\", \"度假\", \"出游\", \n",
    "    \"探险\", \"游览\", \"美景\", \"景区\", \"名胜\", \"胜地\", \"行程\", \"攻略\", \"路线\", \"预订\", \n",
    "    \"游客\", \"导游\", \"走走\", \"好玩\", \"放松\", \"休闲\", \"太美了\", \"必须去\", \"不能错过\", \"好想去\", \n",
    "    \"真的不错\", \"绝了\", \"爱了\", \"值得一去\"\n",
    "]\n",
    "emojis = [\"[比心]\", \"[赞]\", \"[强]\", \"[舔屏]\", \"[爱心]\", \"[送心]\", \"[玫瑰]\"]  # 示例表情符号\n",
    "special_phrases = [\"【发表图片】\"]  # 包含发表图片的情况\n",
    "\n",
    "def label_by_keywords(comment, keywords, emojis, special_phrases):\n",
    "    # 检查是否包含 @ 符号\n",
    "    if \"@\" in comment:\n",
    "        return 1\n",
    "    \n",
    "    # 检查是否包含表情符号\n",
    "    for emoji in emojis:\n",
    "        if emoji in comment:\n",
    "            return 1\n",
    "    \n",
    "    # 检查是否包含特殊短语，如 【发表图片】\n",
    "    for phrase in special_phrases:\n",
    "        if phrase in comment:\n",
    "            return 1\n",
    "    \n",
    "    # 检查是否包含关键词\n",
    "    for keyword in keywords:\n",
    "        if keyword in comment:\n",
    "            return 1\n",
    "    \n",
    "    # 如果以上条件都不满足，标注为 0\n",
    "    return 0\n",
    "\n",
    "# 重新标注数据\n",
    "data['label'] = data['评论'].apply(lambda x: label_by_keywords(str(x), keywords, emojis, special_phrases))\n",
    "\n",
    "# 移除重复评论和空白评论\n",
    "data_cleaned = data.dropna(subset=['评论']).drop_duplicates(subset=['评论'])\n",
    "\n",
    "# 查看数据的前几行\n",
    "print(data_cleaned.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7f992c2c-af5d-4422-9028-9fb9091b1d63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1148, 2340)\n"
     ]
    }
   ],
   "source": [
    "# 对评论进行分词处理\n",
    "data_cleaned['评论_分词'] = data_cleaned['评论'].apply(lambda x: \" \".join(jieba.cut(x)))\n",
    "\n",
    "# 使用TF-IDF对文本进行向量化\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=5000)\n",
    "X = tfidf_vectorizer.fit_transform(data_cleaned['评论_分词'])\n",
    "\n",
    "# 查看处理后的矩阵形状\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6367f4fd-7c62-4425-a9ec-2058f1eb6ba0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集大小: (918, 2340)\n",
      "测试集大小: (230, 2340)\n"
     ]
    }
   ],
   "source": [
    "#构建训练集和测试集\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 假设你已经有了 TF-IDF 处理后的特征矩阵 X 和标签 y\n",
    "y = data_cleaned['label']\n",
    "\n",
    "# 将数据集划分为训练集和测试集\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 输出训练集和测试集的形状\n",
    "print(\"训练集大小:\", X_train.shape)\n",
    "print(\"测试集大小:\", X_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7ad5e121-4484-4d45-89e1-796c53fd0814",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.64      0.71        95\n",
      "           1       0.78      0.87      0.82       135\n",
      "\n",
      "    accuracy                           0.78       230\n",
      "   macro avg       0.78      0.76      0.76       230\n",
      "weighted avg       0.78      0.78      0.77       230\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#使用支持向量机 (SVM) 模型对训练集数据进行训练\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# 初始化SVM模型\n",
    "svm_model = SVC(kernel='linear', random_state=42)\n",
    "\n",
    "# 训练模型\n",
    "svm_model.fit(X_train, y_train)\n",
    "\n",
    "# 在测试集上进行预测\n",
    "y_pred = svm_model.predict(X_test)\n",
    "\n",
    "# 输出分类报告\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "bb42242e-4697-4e95-bf8e-f6e9da9c86c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label\n",
      "1    1400\n",
      "0      20\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(data['label'].value_counts())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
