{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46482552-2f87-4326-a666-8500887cd55e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import jieba\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# 假设我们要处理的数据文件已经上传并读取\n",
    "file_path = 'Blossoms_Food_Tiktok4.xlsx'\n",
    "data = pd.read_excel(file_path)\n",
    "\n",
    "# 扩展后的关键词列表\n",
    "keywords = [\n",
    "    \"打卡了\", \"刚去\", \"吃了\", \"去过\", \"吃过\", \"好吃\", \"去吃\", \"想吃\", \"超想吃\", \"度假\", \"出游\",\n",
    "    \"旅游\", \"打卡\", \"景点\", \"想去\", \"去玩\", \"参观\", \"游玩\", \"去看看\", \"旅行\", \"度假\", \"出游\", \n",
    "    \"探险\", \"游览\", \"美景\", \"景区\", \"名胜\", \"胜地\", \"行程\", \"攻略\", \"路线\", \"预订\", \n",
    "    \"游客\", \"导游\", \"走走\", \"好玩\", \"放松\", \"休闲\", \"太美了\", \"必须去\", \"不能错过\", \"好想去\", \n",
    "    \"真的不错\", \"绝了\", \"爱了\", \"值得一去\"\n",
    "]\n",
    "emojis = [\"[比心]\", \"[赞]\", \"[强]\", \"[舔屏]\", \"[爱心]\", \"[送心]\", \"[玫瑰]\"]  # 示例表情符号\n",
    "special_phrases = [\"【发表图片】\"]  # 包含发表图片的情况\n",
    "\n",
    "def label_by_keywords(comment, keywords, emojis, special_phrases):\n",
    "    # 检查是否包含 @ 符号\n",
    "    if \"@\" in comment:\n",
    "        return 1\n",
    "    \n",
    "    # 检查是否包含表情符号\n",
    "    for emoji in emojis:\n",
    "        if emoji in comment:\n",
    "            return 1\n",
    "    \n",
    "    # 检查是否包含特殊短语，如 【发表图片】\n",
    "    for phrase in special_phrases:\n",
    "        if phrase in comment:\n",
    "            return 1\n",
    "    \n",
    "    # 检查是否包含关键词\n",
    "    for keyword in keywords:\n",
    "        if keyword in comment:\n",
    "            return 1\n",
    "    \n",
    "    # 如果以上条件都不满足，标注为 0\n",
    "    return 0\n",
    "\n",
    "# 重新标注数据\n",
    "data['label'] = data['评论'].apply(lambda x: label_by_keywords(str(x), keywords, emojis, special_phrases))\n",
    "\n",
    "# 移除重复评论和空白评论\n",
    "data_cleaned = data.dropna(subset=['评论']).drop_duplicates(subset=['评论'])\n",
    "\n",
    "# 对评论进行分词处理\n",
    "data_cleaned['评论_分词'] = data_cleaned['评论'].apply(lambda x: \" \".join(jieba.cut(x)))\n",
    "\n",
    "# 使用TF-IDF对文本进行向量化\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=5000)\n",
    "X = tfidf_vectorizer.fit_transform(data_cleaned['评论_分词'])\n",
    "\n",
    "# 构建训练集和测试集\n",
    "y = data_cleaned['label']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 初始化随机森林模型\n",
    "rf_model = RandomForestClassifier(class_weight='balanced', random_state=42)\n",
    "\n",
    "# 训练模型\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# 在测试集上进行预测\n",
    "y_pred = rf_model.predict(X_test)\n",
    "\n",
    "# 输出分类报告\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
